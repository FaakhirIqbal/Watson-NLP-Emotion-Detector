{"cells": [{"metadata": {}, "cell_type": "code", "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='ae1a755d-e162-4f07-9f5a-130d2280e78e', project_access_token='p-aa90b9b21de435c3f4c94494a24b5c5e69d030f8')\npc = project.project_context", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "This notebook demonstrates how to train entity extraction models using Watson NLP.\n\nThe dataset has been downloaded and saved in the [Box folder - training.json](https://ibm.box.com/s/llw7q2gzwbqhgt1h7ek5s0d1mulb0uxx) and [Box folder - dev.json](https://ibm.box.com/s/euz5fpn7jmx7um2giopczcct4lk9uyv3) for you. The text data are labeled with types `GeographicFeature`, `Location`, or `Duration`.\n\n\n## What you'll learn in this notebook\n\nWatson NLP implements state-of-the-art classification algorithms from three different families: \n- Classic machine learning using CRF (Conditional Random Field)\n- Deep learning using BiLSTM (Bidirectional Long Short Term Memory)\n- A transformer-based algorithm using the Google BERT multilingual model \n\nIn this notebook, you'll learn how to:\n\n- **Prepare your data** so that it can be used as training data for the Watson NLP classification algorithms.\n- **Train a custom CRF model** using `watson_nlp.blocks.entity_mentions.SIRE`.\n- **Train a BiLSTM** using `watson_nlp.blocks.entity_mentions.BiLSTM`.\n- **Train a BERT** using `watson_nlp.blocks.entity_mentions.BERT`.\n- **Store and load models** as an asset of a Watson Studio project.\n\n## Table of Contents\n\n\n1.\t[Before You Start](#beforeYouStart)\n1.  [Prepare Training](#prepareTraining)\n1.  [Model Building](#buildModel)\n    1. [SIRE Training](#sire)\n    1. [BiLSTM Training](#bilstm)\n    1. [BERT](#bert)\n1.  [Summary](#summary)"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"beforeYouStart\"></a>\n## Before You Start\n\n<div class=\"alert alert-block alert-danger\">\n<b>Stop kernel of other notebooks.</b></div>\n\n**Note:** If you have other notebooks currently running with the _Default Python 3.8 + Watson NLP XS_ environment, **stop their kernels** before running this notebook. All these notebooks share the same runtime environment, and if they are running in parallel, you may encounter memory issues. To stop the kernel of another notebook, open that notebook, and select _File > Stop Kernel_.\n\n<div class=\"alert alert-block alert-warning\">\n<b>Set Project token.</b></div>\n\nBefore you can begin working on this notebook in Watson Studio in Cloud Pak for Data as a Service, you need to ensure that the project token is set so that you can access the project assets via the notebook.\n\nWhen this notebook is added to the project, a project access token should be inserted at the top of the notebook in a code cell. If you do not see the cell above, add the token to the notebook by clicking **More > Insert project token** from the notebook action bar.  By running the inserted hidden code cell, a project object is created that you can use to access project resources.\n\n![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> Cell execution</div>\n\nNote that you can step through the notebook execution cell by cell, by selecting Shift-Enter. Or you can execute the entire notebook by selecting **Cell -> Run All** from the menu."}, {"metadata": {}, "cell_type": "code", "source": "import json\nimport pandas as pd\nimport watson_nlp\nfrom watson_nlp import data_model as dm\nfrom watson_nlp.toolkit.entity_mentions_utils import prepare_train_from_json, create_iob_labels", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Silence Tensorflow warnings\nimport tensorflow as tf\ntf.get_logger().setLevel('ERROR')\ntf.autograph.set_verbosity(0)", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Load a syntax model to split the text into sentences and tokens\nsyntax_model = watson_nlp.load(watson_nlp.download('syntax_izumo_en_stock'))", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"prepareTraining\"></a>\n### Preparing Training Data"}, {"metadata": {}, "cell_type": "markdown", "source": "The dataset is required to have a dictionary format as follows:\n```\n[\n  {\n    \"id\": 1,\n    \"text\": \"This waterfall is actually hours away from Portland, basically in California.\",\n    \"mentions\": \n    [\n      {\n        \"text\": \"waterfall\", \"type\": \"GeographicFeature\", \n        \"location\": \n          {\n            \"begin\": 5, \n            \"end\": 14\n          }\n      },\n      {\n        \"text\": \"Portland\", \n        \"type\": \"Location\", \n        \"location\": \n          {\n            \"begin\": 43, \n            \"end\": 51\n          }\n      },\n      {\n        \"text\": \"California\", \n        \"type\": \"Location\", \n        \"location\": \n          {\n            \"begin\": 66, \n            \"end\": 76\n          }\n       }\n    ]\n  },\n  ...\n]\n```"}, {"metadata": {}, "cell_type": "markdown", "source": "Since the data is already formatted correctly, the following process is needed to read the JSON data files from Watson Studio project assets and save them to the runtime working directory where they will be used as input for training the models."}, {"metadata": {}, "cell_type": "code", "source": "buffer = project.get_file(\"entity_train.json\")\npd.read_json(buffer).to_json('train.json', orient='records')\nbuffer = project.get_file(\"entity_dev.json\")\npd.read_json(buffer).to_json('dev.json', orient='records')\nbuffer = project.get_file(\"entity_test.json\")\npd.read_json(buffer).to_json('test.json', orient='records')", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The text inputs will be converted into a streaming array where the text is broken down by the syntax model."}, {"metadata": {}, "cell_type": "code", "source": "train_data = dm.DataStream.from_json_array(\"train.json\")\ntrain_iob_stream = prepare_train_from_json(train_data, syntax_model)\ndev_data = dm.DataStream.from_json_array(\"dev.json\")\ndev_iob_stream = prepare_train_from_json(dev_data, syntax_model)", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"buildModel\"></a>\n## Model Building"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"sire\"></a>\n### SIRE Training"}, {"metadata": {}, "cell_type": "markdown", "source": "You can train SIRE models using either CRF & Maximum Entropy template as base models. Between the two, CRF based template takes longer to train but gives better results.\n\nThese algorithms accept a set of featured in the form of dictionaries and regular expressions. A set of predefined feature extractors are provided for multiple languages, and you can also define your own features."}, {"metadata": {}, "cell_type": "code", "source": "#help(watson_nlp.blocks.entity_mentions.SIRE.train)", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Download the algorithm template\nmentions_train_template = watson_nlp.load(watson_nlp.download('file_path_entity-mentions_sire_multi_template-crf'))\n# Download the feature extractor\ndefault_feature_extractor = watson_nlp.load(watson_nlp.download('feature-extractor_rbr_entity-mentions_sire_en_stock'))", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Train the model\nsire_custom = watson_nlp.blocks.entity_mentions.SIRE.train(train_iob_stream, \n                                                           'en', \n                                                           mentions_train_template,\n                                                           feature_extractors=[default_feature_extractor])", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "Initializing viterbi classifier\n\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\nGet Feature str 534\nDone get feature str 534\ndone. [25\u001b[33mg\u001b[0m192\u001b[33mm\u001b[0m1012\u001b[33mk\u001b[0m,1\u001b[33mg\u001b[0m756\u001b[33mm\u001b[0m904\u001b[33mk\u001b[0m]\ngramSize = 2\nnumber of processes: 5\nInitial processing:  (# of words: 980, # of sentences: 98)\nsenIndex[1] = 19, wordIndex = 200\nsenIndex[2] = 38, wordIndex = 393\nsenIndex[3] = 58, wordIndex = 593\nsenIndex[4] = 78, wordIndex = 793\nsenIndex[5] = 97, wordIndex = 980\n\u001b[32m[ME_CRF::scaleModel]\u001b[0m Updater -- l1=\u001b[32m0.1\u001b[0m, l2=\u001b[32m0.005\u001b[0m, history size=\u001b[32m5\u001b[0m, progress windows size \u001b[32m20\u001b[0m\n Iteration           Obj             WErr                         Timing       %Eff        Per thread timing\n                 1338.85     15.00/100.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n         0      379.75      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n         1       92.48      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n         2       54.19      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n         3       37.79      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n         4       28.36      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n         5       22.84      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n         6       19.60      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n         7       17.53      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n         8       16.03      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n         9       14.54      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n        10       13.10      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n        11       11.46      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n        12       10.51      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n        13        8.76      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n        14        8.15      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n        15        7.78      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n        16        7.70      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n        17        7.28      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n        18        7.19      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\n        19        7.10      0.00/  0.00             E:0.00 s, M:0.00 s.       1.00 [m:0.00, M:0.00, av:0.00]\nNot enough progress in the last 5 iters.. converged.\n    Thread     Total      Wait Effective      %Eff         #Sents/sec\n         0      0.04      0.00      0.04      1.00            10837.44\n         1      0.05      0.00      0.05      1.00            10180.16\n         2      0.04      0.00      0.04      1.00             9697.45\n         3      0.04      0.00      0.04      1.00             9473.89\n         4      0.04      0.00      0.04      1.00             9382.05\nParent: the end!\nInitializing viterbi classifier\n\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "The following code will save the custom model to Watson Studio by using the project library."}, {"metadata": {}, "cell_type": "code", "source": "# Save the model\nproject.save_data('sire_custom', data=sire_custom.as_file_like_object(), overwrite=True)", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "Saved 166 features.\n", "name": "stderr"}, {"output_type": "execute_result", "execution_count": 9, "data": {"text/plain": "{'file_name': 'sire_custom',\n 'message': 'File saved to project storage.',\n 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n 'asset_id': '8b197850-caca-4071-ad73-b60d639c9f3c'}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Let's run the model on one example input."}, {"metadata": {}, "cell_type": "code", "source": "text = pd.read_json('dev.json')['text'][1]\ntext", "execution_count": 60, "outputs": [{"output_type": "execute_result", "execution_count": 60, "data": {"text/plain": "'I work at California and Portland.'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Run the model\nsyntax_result = syntax_model.run(text)\nsire_result = sire_custom.run(syntax_result)\nsire_result", "execution_count": 64, "outputs": [{"output_type": "execute_result", "execution_count": 64, "data": {"text/plain": "{\n  \"mentions\": [\n    {\n      \"span\": {\n        \"begin\": 10,\n        \"end\": 20,\n        \"text\": \"California\"\n      },\n      \"type\": \"Duration\",\n      \"producer_id\": null,\n      \"confidence\": 0.9749692485802756,\n      \"mention_type\": \"MENTT_UNSET\",\n      \"mention_class\": \"MENTC_UNSET\",\n      \"role\": \"\"\n    },\n    {\n      \"span\": {\n        \"begin\": 25,\n        \"end\": 33,\n        \"text\": \"Portland\"\n      },\n      \"type\": \"Location\",\n      \"producer_id\": null,\n      \"confidence\": 0.9673596800654085,\n      \"mention_type\": \"MENTT_UNSET\",\n      \"mention_class\": \"MENTC_UNSET\",\n      \"role\": \"\"\n    }\n  ],\n  \"producer_id\": {\n    \"name\": \"SIRE Entity Mentions\",\n    \"version\": \"0.0.1\"\n  }\n}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Now you are able to run the trained models on new data. You will run the models on the test data so that the results can also be used for model evaluation."}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "# Execute the model and generate the quality report\npreprocess_func = lambda raw_doc: syntax_model.run(raw_doc)\nquality_report = sire_custom.evaluate_quality('test.json', preprocess_func)\n\n# Print the quality report\nprint(json.dumps(quality_report, indent=4))", "execution_count": 40, "outputs": [{"output_type": "stream", "text": "WARNING: Only Micro_avg metrics could be calculated based on the information available for this block type.\n", "name": "stderr"}, {"output_type": "stream", "text": "{\n    \"per_class_confusion_matrix\": {\n        \"GeographicFeature\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 10,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Number\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 2,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Person\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 1,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Time\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 2,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Location\": {\n            \"true_positive\": 1,\n            \"false_positive\": 25,\n            \"false_negative\": 12,\n            \"precision\": 0.038461538461538464,\n            \"recall\": 0.07692307692307693,\n            \"f1\": 0.05128205128205129\n        },\n        \"Date\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 14,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Money\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 1,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Measure\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 8,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Ordinal\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 3,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Duration\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 8,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Percent\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 1,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Facility\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 4,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"JobTitle\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 3,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Organization\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 3,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        }\n    },\n    \"macro_true_positive\": null,\n    \"macro_false_positive\": null,\n    \"macro_false_negative\": null,\n    \"macro_precision\": 0.0027472527472527475,\n    \"macro_recall\": 0.005494505494505495,\n    \"macro_f1\": 0.0036630036630036634,\n    \"micro_precision\": 0.038461538461538464,\n    \"micro_recall\": 0.0136986301369863,\n    \"micro_f1\": 0.0202020202020202,\n    \"overall_tp\": 1,\n    \"overall_fp\": 25,\n    \"overall_fn\": 72,\n    \"detailed_metrics\": [],\n    \"micro_precision_partial_match\": 0.0,\n    \"micro_recall_partial_match\": 0.0,\n    \"micro_f1_partial_match\": 0.0\n}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"bilstm\"></a>\n### BiLSTM Training"}, {"metadata": {}, "cell_type": "markdown", "source": "The deep-learning algorithm used in this block performs sequence labelling based on the BiLSTM architecture followed by a CRF layer. It uses GloVe embeddings as features."}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "#help(watson_nlp.blocks.entity_mentions.BiLSTM.train)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Download the GloVe model to be used as embeddings in the BiLSTM\nglove_model = watson_nlp.load(watson_nlp.download('embedding_glove_en_stock'))", "execution_count": 30, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "# Train the model\nbilstm_model = watson_nlp.blocks.entity_mentions.BiLSTM.train(train_iob_stream,\n                                                              dev_iob_stream,\n                                                              glove_model.embedding,\n                                                              num_train_epochs=3)", "execution_count": 34, "outputs": [{"output_type": "stream", "text": "4/4 [==============================] - 8s 2s/step - loss: 1.7898 - val_loss: 1.6067\n4/4 [==============================] - 0s 58ms/step - loss: 1.5230 - val_loss: 1.3603\n4/4 [==============================] - 0s 54ms/step - loss: 1.3044 - val_loss: 1.1661\n4/4 [==============================] - 0s 54ms/step - loss: 1.1144 - val_loss: 1.0205\n4/4 [==============================] - 0s 54ms/step - loss: 0.9900 - val_loss: 0.9157\n4/4 [==============================] - 0s 61ms/step - loss: 0.8905 - val_loss: 0.8400\n4/4 [==============================] - 0s 54ms/step - loss: 0.8243 - val_loss: 0.7832\n4/4 [==============================] - 0s 54ms/step - loss: 0.7833 - val_loss: 0.7378\n4/4 [==============================] - 0s 54ms/step - loss: 0.7289 - val_loss: 0.6989\n4/4 [==============================] - 0s 53ms/step - loss: 0.6975 - val_loss: 0.6650\n4/4 [==============================] - 0s 56ms/step - loss: 0.6652 - val_loss: 0.6349\n4/4 [==============================] - 0s 54ms/step - loss: 0.6328 - val_loss: 0.6082\n4/4 [==============================] - 0s 55ms/step - loss: 0.6166 - val_loss: 0.5844\n4/4 [==============================] - 0s 56ms/step - loss: 0.6004 - val_loss: 0.5630\n4/4 [==============================] - 0s 68ms/step - loss: 0.5666 - val_loss: 0.5434\n4/4 [==============================] - 0s 57ms/step - loss: 0.5585 - val_loss: 0.5253\n4/4 [==============================] - 0s 54ms/step - loss: 0.5209 - val_loss: 0.5085\n4/4 [==============================] - 0s 54ms/step - loss: 0.5067 - val_loss: 0.4929\n4/4 [==============================] - 0s 78ms/step - loss: 0.5006 - val_loss: 0.4784\n4/4 [==============================] - 0s 54ms/step - loss: 0.4890 - val_loss: 0.4648\n4/4 [==============================] - 0s 54ms/step - loss: 0.4784 - val_loss: 0.4520\n4/4 [==============================] - 0s 53ms/step - loss: 0.4710 - val_loss: 0.4398\n4/4 [==============================] - 0s 54ms/step - loss: 0.4459 - val_loss: 0.4281\n4/4 [==============================] - 0s 61ms/step - loss: 0.4394 - val_loss: 0.4170\n4/4 [==============================] - 0s 54ms/step - loss: 0.4280 - val_loss: 0.4065\n4/4 [==============================] - 0s 55ms/step - loss: 0.4184 - val_loss: 0.3963\n4/4 [==============================] - 0s 57ms/step - loss: 0.4279 - val_loss: 0.3865\n4/4 [==============================] - 0s 64ms/step - loss: 0.4020 - val_loss: 0.3771\n4/4 [==============================] - 0s 53ms/step - loss: 0.3906 - val_loss: 0.3682\n4/4 [==============================] - 0s 61ms/step - loss: 0.3735 - val_loss: 0.3597\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "The following code will save the custom model to Watson Studio by using the project library."}, {"metadata": {}, "cell_type": "code", "source": "# Save the model\nproject.save_data('bilstm_custom', data=bilstm_custom.as_file_like_object(), overwrite=True)", "execution_count": 27, "outputs": [{"output_type": "execute_result", "execution_count": 27, "data": {"text/plain": "{'file_name': 'bilstm_custom',\n 'message': 'File saved to project storage.',\n 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n 'asset_id': 'a1420859-9a8e-4905-8448-e1a33bd6673a'}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Let's run the model on one example input."}, {"metadata": {}, "cell_type": "code", "source": "# Run the model\nsyntax_result = syntax_model.run(text)\nbilstm_result = bilstm_custom.run(syntax_result)\nbilstm_result", "execution_count": 62, "outputs": [{"output_type": "execute_result", "execution_count": 62, "data": {"text/plain": "{\n  \"mentions\": [\n    {\n      \"span\": {\n        \"begin\": 10,\n        \"end\": 20,\n        \"text\": \"California\"\n      },\n      \"type\": \"Duration\",\n      \"producer_id\": {\n        \"name\": \"BiLSTM Entity Mentions\",\n        \"version\": \"1.0.0\"\n      },\n      \"confidence\": 0.13714201748371124,\n      \"mention_type\": \"MENTT_UNSET\",\n      \"mention_class\": \"MENTC_UNSET\",\n      \"role\": \"\"\n    },\n    {\n      \"span\": {\n        \"begin\": 25,\n        \"end\": 33,\n        \"text\": \"Portland\"\n      },\n      \"type\": \"Location\",\n      \"producer_id\": {\n        \"name\": \"BiLSTM Entity Mentions\",\n        \"version\": \"1.0.0\"\n      },\n      \"confidence\": 0.3342318534851074,\n      \"mention_type\": \"MENTT_UNSET\",\n      \"mention_class\": \"MENTC_UNSET\",\n      \"role\": \"\"\n    }\n  ],\n  \"producer_id\": {\n    \"name\": \"BiLSTM Entity Mentions\",\n    \"version\": \"1.0.0\"\n  }\n}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Now you are able to run the trained models on new data. You will run the models on the test data so that the results can also be used for model evaluation."}, {"metadata": {}, "cell_type": "code", "source": "# Execute the model and generate the quality report\npreprocess_func = lambda raw_doc: syntax_model.run(raw_doc)\nquality_report = bilstm_custom.evaluate_quality('test.json', preprocess_func)\n\n# Print the quality report\nprint(json.dumps(quality_report, indent=4))", "execution_count": 39, "outputs": [{"output_type": "stream", "text": "WARNING: Only Micro_avg metrics could be calculated based on the information available for this block type.\n", "name": "stderr"}, {"output_type": "stream", "text": "{\n    \"per_class_confusion_matrix\": {\n        \"GeographicFeature\": {\n            \"true_positive\": 0,\n            \"false_positive\": 14,\n            \"false_negative\": 10,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Location\": {\n            \"true_positive\": 3,\n            \"false_positive\": 9,\n            \"false_negative\": 10,\n            \"precision\": 0.25,\n            \"recall\": 0.23076923076923078,\n            \"f1\": 0.24000000000000002\n        },\n        \"Number\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 2,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Person\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 1,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Time\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 2,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Date\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 14,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Money\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 1,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Measure\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 8,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Ordinal\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 3,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Duration\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 8,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Percent\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 1,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Facility\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 4,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"JobTitle\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 3,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Organization\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 3,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        }\n    },\n    \"macro_true_positive\": null,\n    \"macro_false_positive\": null,\n    \"macro_false_negative\": null,\n    \"macro_precision\": 0.017857142857142856,\n    \"macro_recall\": 0.016483516483516484,\n    \"macro_f1\": 0.017142857142857144,\n    \"micro_precision\": 0.11538461538461539,\n    \"micro_recall\": 0.0410958904109589,\n    \"micro_f1\": 0.06060606060606061,\n    \"overall_tp\": 3,\n    \"overall_fp\": 23,\n    \"overall_fn\": 70,\n    \"detailed_metrics\": [],\n    \"micro_precision_partial_match\": 0.0,\n    \"micro_recall_partial_match\": 0.0,\n    \"micro_f1_partial_match\": 0.0\n}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"bert\"></a>\n### BERT Training"}, {"metadata": {}, "cell_type": "markdown", "source": "The algorithm used is a Transformer-based sequence labeling algorithm using the BERT architecture."}, {"metadata": {}, "cell_type": "code", "source": "# Download and load the pretrained model resource\npretrained_model_resource = watson_nlp.load(watson_nlp.download('pretrained-model_bert_multi_bert_multi_cased'))\n\n# Labels you are interested in training the model for\nlabels = ['Duration', 'Location', 'GeographicFeature']\n\n# Generate IOB labels: B-Duration, I-Duration, B-Location, I-Location\niob_labels = create_iob_labels(labels)\n\n# Train the model\nbert_custom = watson_nlp.blocks.entity_mentions.BERT.train(train_iob_stream,\n                                                        dev_iob_stream,\n                                                        iob_labels,\n                                                        pretrained_model_resource,\n                                                        do_lower_case=True,\n                                                        num_train_epochs=10,\n                                                        train_batch_size=1,\n                                                        dev_batch_size=1,\n                                                        keep_model_artifacts=False)", "execution_count": 57, "outputs": [{"output_type": "stream", "text": "Epoch 1/10\n98/98 [==============================] - 136s 1s/step - loss: 103.3422 - test_accuracy: 0.8076 - val_loss: 3.8633 - val_test_accuracy: 0.9883\nEpoch 2/10\n98/98 [==============================] - 124s 1s/step - loss: 1.0149 - test_accuracy: 0.9991 - val_loss: 0.0366 - val_test_accuracy: 1.0000\nEpoch 3/10\n98/98 [==============================] - 126s 1s/step - loss: 0.0403 - test_accuracy: 1.0000 - val_loss: 0.0134 - val_test_accuracy: 1.0000\nEpoch 4/10\n98/98 [==============================] - 124s 1s/step - loss: 0.0204 - test_accuracy: 1.0000 - val_loss: 0.0089 - val_test_accuracy: 1.0000\nEpoch 5/10\n98/98 [==============================] - 124s 1s/step - loss: 0.0146 - test_accuracy: 1.0000 - val_loss: 0.0068 - val_test_accuracy: 1.0000\nEpoch 6/10\n98/98 [==============================] - 125s 1s/step - loss: 0.0117 - test_accuracy: 1.0000 - val_loss: 0.0057 - val_test_accuracy: 1.0000\nEpoch 7/10\n98/98 [==============================] - 123s 1s/step - loss: 0.0101 - test_accuracy: 1.0000 - val_loss: 0.0050 - val_test_accuracy: 1.0000\nEpoch 8/10\n98/98 [==============================] - 125s 1s/step - loss: 0.0090 - test_accuracy: 1.0000 - val_loss: 0.0045 - val_test_accuracy: 1.0000\nEpoch 9/10\n98/98 [==============================] - 124s 1s/step - loss: 0.0083 - test_accuracy: 1.0000 - val_loss: 0.0043 - val_test_accuracy: 1.0000\nEpoch 10/10\n98/98 [==============================] - 124s 1s/step - loss: 0.0080 - test_accuracy: 1.0000 - val_loss: 0.0042 - val_test_accuracy: 1.0000\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "The following code will save the custom model to Watson Studio by using the project library."}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "# Save the model\nproject.save_data('bert_custom', data=bert_custom.as_file_like_object(), overwrite=True)", "execution_count": 58, "outputs": [{"output_type": "stream", "text": "WARNING:absl:Found untraced functions such as word_embeddings_layer_call_fn, word_embeddings_layer_call_and_return_conditional_losses, embedding_postprocessor_layer_call_fn, embedding_postprocessor_layer_call_and_return_conditional_losses, encoder_layer_call_fn while saving (showing 5 of 810). These functions will not be directly callable after loading.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fbc88c6a850> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fbcf8a15c10> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fbc88c80d30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fbc88bcf130> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fbcf89a47c0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fbcf8967640> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fbcf8935130> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fbce41e2b50> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fbce41b4130> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fbce4177760> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fbce4138ee0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fbce40874c0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n", "name": "stderr"}, {"output_type": "execute_result", "execution_count": 58, "data": {"text/plain": "{'file_name': 'bert_custom',\n 'message': 'File saved to project storage.',\n 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n 'asset_id': '445cdcc2-9390-4f41-85c4-f5c11db2d86c'}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Let's run the model on one example input."}, {"metadata": {}, "cell_type": "code", "source": "# Run the model\nsyntax_result = syntax_model.run(text)\nbert_result = bert_custom.run(syntax_result)\nbert_result", "execution_count": 61, "outputs": [{"output_type": "execute_result", "execution_count": 61, "data": {"text/plain": "{\n  \"mentions\": [\n    {\n      \"span\": {\n        \"begin\": 10,\n        \"end\": 20,\n        \"text\": \"California\"\n      },\n      \"type\": \"Duration\",\n      \"producer_id\": {\n        \"name\": \"BERT Entity Mentions\",\n        \"version\": \"0.0.1\"\n      },\n      \"confidence\": 0.9996285438537598,\n      \"mention_type\": \"MENTT_UNSET\",\n      \"mention_class\": \"MENTC_UNSET\",\n      \"role\": \"\"\n    },\n    {\n      \"span\": {\n        \"begin\": 25,\n        \"end\": 33,\n        \"text\": \"Portland\"\n      },\n      \"type\": \"Location\",\n      \"producer_id\": {\n        \"name\": \"BERT Entity Mentions\",\n        \"version\": \"0.0.1\"\n      },\n      \"confidence\": 0.9997851252555847,\n      \"mention_type\": \"MENTT_UNSET\",\n      \"mention_class\": \"MENTC_UNSET\",\n      \"role\": \"\"\n    }\n  ],\n  \"producer_id\": {\n    \"name\": \"BERT Entity Mentions\",\n    \"version\": \"0.0.1\"\n  }\n}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Now you are able to run the trained models on new data. You will run the models on the test data so that the results can also be used for model evaluation."}, {"metadata": {}, "cell_type": "code", "source": "# Execute the model and generate the quality report\npreprocess_func = lambda raw_doc: syntax_model.run(raw_doc)\nquality_report = bert_custom.evaluate_quality('test.json', preprocess_func)\n\n# Print the quality report\nprint(json.dumps(quality_report, indent=4))", "execution_count": 63, "outputs": [{"output_type": "stream", "text": "WARNING:TLKIT:WARNING: Only Micro_avg metrics could be calculated based on the information available for this block type.\n", "name": "stderr"}, {"output_type": "stream", "text": "{\n    \"per_class_confusion_matrix\": {\n        \"GeographicFeature\": {\n            \"true_positive\": 0,\n            \"false_positive\": 1,\n            \"false_negative\": 10,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Number\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 2,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Person\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 1,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Time\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 2,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Date\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 14,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Money\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 1,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Measure\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 8,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Location\": {\n            \"true_positive\": 2,\n            \"false_positive\": 8,\n            \"false_negative\": 11,\n            \"precision\": 0.2,\n            \"recall\": 0.15384615384615385,\n            \"f1\": 0.17391304347826086\n        },\n        \"Ordinal\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 3,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Duration\": {\n            \"true_positive\": 0,\n            \"false_positive\": 7,\n            \"false_negative\": 8,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Percent\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 1,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Facility\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 4,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"JobTitle\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 3,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        },\n        \"Organization\": {\n            \"true_positive\": 0,\n            \"false_positive\": 0,\n            \"false_negative\": 3,\n            \"precision\": 0.0,\n            \"recall\": 0.0,\n            \"f1\": 0.0\n        }\n    },\n    \"macro_true_positive\": null,\n    \"macro_false_positive\": null,\n    \"macro_false_negative\": null,\n    \"macro_precision\": 0.014285714285714287,\n    \"macro_recall\": 0.01098901098901099,\n    \"macro_f1\": 0.012422360248447204,\n    \"micro_precision\": 0.1111111111111111,\n    \"micro_recall\": 0.0273972602739726,\n    \"micro_f1\": 0.04395604395604396,\n    \"overall_tp\": 2,\n    \"overall_fp\": 16,\n    \"overall_fn\": 71,\n    \"detailed_metrics\": [],\n    \"micro_precision_partial_match\": 0.0,\n    \"micro_recall_partial_match\": 0.0,\n    \"micro_f1_partial_match\": 0.0\n}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"summary\"></a>\n## 5. Summary"}, {"metadata": {}, "cell_type": "markdown", "source": "<span style=\"color:blue\">This notebook shows you how to use the Watson NLP library and how quickly and easily you can train and run different entity extraction models using Watson NLP.</span>"}, {"metadata": {}, "cell_type": "markdown", "source": "Please note that this content is made available to foster Embedded AI technology adoption. The content may include systems & methods pending patent with USPTO and protected under US Patent Laws. For redistribution of this content, IBM will use release process. For any questions please log an issue in the [GitHub](https://github.com/ibm-build-labs/Watson-NLP). \n\nDeveloped by IBM Build Lab \n\nCopyright - 2022 IBM Corporation "}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}