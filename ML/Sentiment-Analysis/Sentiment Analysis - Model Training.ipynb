{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Training sentiment analysis model using Watson NLP"}, {"metadata": {}, "cell_type": "markdown", "source": "This notebook demonstrates how to train sentiment analysis model on movie reviews using Watson NLP.\n\nThe data that is used in this notebook is taken from the `Kaggle`, https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis with license CC0: Public Domain. The dataset has been downsampled for fast execution of the notebook. You can download the downsampled data from [GitHub Repo](https://github.ibm.com/hcbt/Watson-NLP/blob/main/Sentiment-Analysis/movies_small.csv)\n\n### What you'll learn in this notebook\nWatson NLP offers so-called blocks for various NLP tasks. This notebooks shows:\n\n- **Sentiment analysis** with the _Sentiment block_ (`BERT Document Sentiment block`). Sentiment analysis classifies the sentiment of the reviews into positive or negative  sentiment. You will use the Sentiment workflow to train a BERT based sentiment analysis model. Then you will save the trained sentiment analysis model and finally evaluated the trained model on the test dataset for IMDB movie reviews\n\n## Table of Contents\n\n\n1.  [Before you start](#beforeYouStart)\n1.  [Data Loading](#loadData)\n1.  [Data Processing](#processData)\n1.  [Model Building](#buildModel)\n    1. [Train sentiment analysis model using workflow](#trainWorkflow)\n    1. [Save the model/workflow](#saveModel)\n1.  [Model Evaluation](#evaluateModel)\n1.  [Summary](#summary)"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"beforeYouStart\"></a>\n## 1. Before you start"}, {"metadata": {}, "cell_type": "markdown", "source": "<div class=\"alert alert-block alert-danger\">\n<b>Stop kernel of other notebooks.</b></div>\n\n**Note:** If you have other notebooks currently running with the _Default Python 3.8 + Watson NLP XS_ environment, **stop their kernels** before running this notebook. All these notebooks share the same runtime environment, and if they are running in parallel, you may encounter memory issues. To stop the kernel of another notebook, open that notebook, and select _File > Stop Kernel_.\n\n<div class=\"alert alert-block alert-warning\">\n<b>Set Project token.</b></div>\n\nBefore you can begin working on this notebook in Watson Studio in Cloud Pak for Data as a Service, you need to ensure that the project token is set so that you can access the project assets via the notebook.\n\nWhen this notebook is added to the project, a project access token should be inserted at the top of the notebook in a code cell. If you do not see the cell above, add the token to the notebook by clicking **More > Insert project token** from the notebook action bar.  By running the inserted hidden code cell, a project object is created that you can use to access project resources.\n\n![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n\n\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> Cell execution</div>\n\nNote that you can step through the notebook execution cell by cell, by selecting Shift-Enter. Or you can execute the entire notebook by selecting **Cell -> Run All** from the menu."}, {"metadata": {}, "cell_type": "markdown", "source": "Begin by importing and initializing some helper libs that are used throughout the notebook."}, {"metadata": {}, "cell_type": "code", "source": "%%capture\n# word cloud is used to create graphs below\n!pip install wordcloud", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import os, types\nimport pandas as pd\n# we want to show large text snippets to be able to explore the relevant text\npd.options.display.max_colwidth = 400\n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import watson_nlp", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"loadData\"></a>\n## 2. Data Loading (movie reviews)"}, {"metadata": {}, "cell_type": "markdown", "source": "<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> If you want to carry out sentiment analysis on any other dataset, you should first upload the dataset into the project and then update the name of the file in the next cell</div>"}, {"metadata": {}, "cell_type": "markdown", "source": "We load the movie reviews into a DataFrame.\n\nThis data set contains 10000 movie reviews with labels."}, {"metadata": {}, "cell_type": "code", "source": "import os, types\nimport pandas as pd\nbuffer = project.get_file(\"movies_small.csv\")    \nmovies_df = pd.read_csv(buffer)\nmovies_df.head()\n", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "   Unnamed: 0  \\\n0           0   \n1           1   \n2           2   \n3           3   \n4           4   \n\n                                                                                                                                                                                                                                                                                                                                                                                                              text  \\\n0  I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The onl...   \n1  When I put this movie in my DVD player, and sat down with a coke and some chips, I had some expectations. I was hoping that this movie would contain some of the strong-points of the first movie: Awsome animation, good flowing story, excellent voice cast, funny comedy and a kick-ass soundtrack. But, to my disappointment, not any of this is to be found in Atlantis: Milo's Return. Had I read some...   \n2  Why do people who do not know what a particular time in the past was like feel the need to try to define that time for others? Replace Woodstock with the Civil War and the Apollo moon-landing with the Titanic sinking and you've got as realistic a flick as this formulaic soap opera populated entirely by low-life trash. Is this what kids who were too young to be allowed to go to Woodstock and wh...   \n3                                                  Even though I have great interest in Biblical movies, I was bored to death every minute of the movie. Everything is bad. The movie is too long, the acting is most of the time a Joke and the script is horrible. I did not get the point in mixing the story about Abraham and Noah together. So if you value your time and sanity stay away from this horror.   \n4  Im a die hard Dads Army fan and nothing will ever change that. I got all the tapes, DVD's and audiobooks and every time i watch/listen to them its brand new. <br /><br />The film. The film is a re run of certain episodes, Man and the hour, Enemy within the gates, Battle School and numerous others with a different edge. Introduction of a new General instead of Captain Square was a brilliant mov...   \n\n   label  \n0      0  \n1      0  \n2      0  \n3      0  \n4      1  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The onl...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>When I put this movie in my DVD player, and sat down with a coke and some chips, I had some expectations. I was hoping that this movie would contain some of the strong-points of the first movie: Awsome animation, good flowing story, excellent voice cast, funny comedy and a kick-ass soundtrack. But, to my disappointment, not any of this is to be found in Atlantis: Milo's Return. Had I read some...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Why do people who do not know what a particular time in the past was like feel the need to try to define that time for others? Replace Woodstock with the Civil War and the Apollo moon-landing with the Titanic sinking and you've got as realistic a flick as this formulaic soap opera populated entirely by low-life trash. Is this what kids who were too young to be allowed to go to Woodstock and wh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Even though I have great interest in Biblical movies, I was bored to death every minute of the movie. Everything is bad. The movie is too long, the acting is most of the time a Joke and the script is horrible. I did not get the point in mixing the story about Abraham and Noah together. So if you value your time and sanity stay away from this horror.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Im a die hard Dads Army fan and nothing will ever change that. I got all the tapes, DVD's and audiobooks and every time i watch/listen to them its brand new. &lt;br /&gt;&lt;br /&gt;The film. The film is a re run of certain episodes, Man and the hour, Enemy within the gates, Battle School and numerous others with a different edge. Introduction of a new General instead of Captain Square was a brilliant mov...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"processData\"></a>\n## 3. Data Processing"}, {"metadata": {}, "cell_type": "markdown", "source": "Helper function to convert the raw data into processed data which can be fed into the sentiment classification model."}, {"metadata": {}, "cell_type": "code", "source": "def convertToList(x):\n    return [x]", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def input_data_prep(df):\n    df['weight'] = 1\n    df.rename(columns={'label': 'labels'}, inplace=True)\n    df = df[['text', 'weight', 'labels']]\n    df['labels'] = df['labels'].replace({0: 'negative', 1: 'positive'})\n#     df['labels'] = df['labels'].str.split(',')\n    df['labels'] = df['labels'].apply(convertToList)\n    display(df.head(5))\n    return df", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "movies_df_processed = input_data_prep(movies_df)\n", "execution_count": 10, "outputs": [{"output_type": "display_data", "data": {"text/plain": "                                                                                                                                                                                                                                                                                                                                                                                                              text  \\\n0  I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The onl...   \n1  When I put this movie in my DVD player, and sat down with a coke and some chips, I had some expectations. I was hoping that this movie would contain some of the strong-points of the first movie: Awsome animation, good flowing story, excellent voice cast, funny comedy and a kick-ass soundtrack. But, to my disappointment, not any of this is to be found in Atlantis: Milo's Return. Had I read some...   \n2  Why do people who do not know what a particular time in the past was like feel the need to try to define that time for others? Replace Woodstock with the Civil War and the Apollo moon-landing with the Titanic sinking and you've got as realistic a flick as this formulaic soap opera populated entirely by low-life trash. Is this what kids who were too young to be allowed to go to Woodstock and wh...   \n3                                                  Even though I have great interest in Biblical movies, I was bored to death every minute of the movie. Everything is bad. The movie is too long, the acting is most of the time a Joke and the script is horrible. I did not get the point in mixing the story about Abraham and Noah together. So if you value your time and sanity stay away from this horror.   \n4  Im a die hard Dads Army fan and nothing will ever change that. I got all the tapes, DVD's and audiobooks and every time i watch/listen to them its brand new. <br /><br />The film. The film is a re run of certain episodes, Man and the hour, Enemy within the gates, Battle School and numerous others with a different edge. Introduction of a new General instead of Captain Square was a brilliant mov...   \n\n   weight      labels  \n0       1  [negative]  \n1       1  [negative]  \n2       1  [negative]  \n3       1  [negative]  \n4       1  [positive]  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>weight</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The onl...</td>\n      <td>1</td>\n      <td>[negative]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>When I put this movie in my DVD player, and sat down with a coke and some chips, I had some expectations. I was hoping that this movie would contain some of the strong-points of the first movie: Awsome animation, good flowing story, excellent voice cast, funny comedy and a kick-ass soundtrack. But, to my disappointment, not any of this is to be found in Atlantis: Milo's Return. Had I read some...</td>\n      <td>1</td>\n      <td>[negative]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why do people who do not know what a particular time in the past was like feel the need to try to define that time for others? Replace Woodstock with the Civil War and the Apollo moon-landing with the Titanic sinking and you've got as realistic a flick as this formulaic soap opera populated entirely by low-life trash. Is this what kids who were too young to be allowed to go to Woodstock and wh...</td>\n      <td>1</td>\n      <td>[negative]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Even though I have great interest in Biblical movies, I was bored to death every minute of the movie. Everything is bad. The movie is too long, the acting is most of the time a Joke and the script is horrible. I did not get the point in mixing the story about Abraham and Noah together. So if you value your time and sanity stay away from this horror.</td>\n      <td>1</td>\n      <td>[negative]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Im a die hard Dads Army fan and nothing will ever change that. I got all the tapes, DVD's and audiobooks and every time i watch/listen to them its brand new. &lt;br /&gt;&lt;br /&gt;The film. The film is a re run of certain episodes, Man and the hour, Enemy within the gates, Battle School and numerous others with a different edge. Introduction of a new General instead of Captain Square was a brilliant mov...</td>\n      <td>1</td>\n      <td>[positive]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Splitting the dataset into test & train. Train dataset will be used to train the sentiment classification model and test dataset will be used to evaluate the model."}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.model_selection import train_test_split\ntrain_orig, test_orig = train_test_split(movies_df, test_size=0.2)\ntrain, test = train_test_split(movies_df_processed, test_size=0.2)", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "train_file = './train_data.json'\ntrain.to_json(train_file, orient='records')\n    \ntest_file = './test_data.json'\ntest.to_json(test_file, orient='records')\n\ntest.head(2)", "execution_count": 12, "outputs": [{"output_type": "execute_result", "execution_count": 12, "data": {"text/plain": "                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n2568  `Mad Dog' Earle is back, along with his sad-sack moll Marie, and that fickle clubfoot Velma. So are Babe and Red, Doc and Big Mac, and even the scenery-chewing mutt Pard. The only thing missing is a good reason for remaking Raoul Walsh's High Sierra 14 years later without rethinking a line or a frame, and doing so with talent noticeably a rung or two down the ladder from that in the original. ...   \n7873  This \"movie\" and I say this lightly, is nothing but pure trash. I feel sorry for those people that actually wasted their money to go see this in theaters..I saw a screener of the movie from a friend and I've regretted it ever since. <br /><br />As a black woman, I am EXTREMELY embarrassed to have seen this. More so, I am extremely horrified that people of other races may have seen this as well...   \n\n      weight      labels  \n2568       1  [positive]  \n7873       1  [negative]  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>weight</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2568</th>\n      <td>`Mad Dog' Earle is back, along with his sad-sack moll Marie, and that fickle clubfoot Velma. So are Babe and Red, Doc and Big Mac, and even the scenery-chewing mutt Pard. The only thing missing is a good reason for remaking Raoul Walsh's High Sierra 14 years later without rethinking a line or a frame, and doing so with talent noticeably a rung or two down the ladder from that in the original. ...</td>\n      <td>1</td>\n      <td>[positive]</td>\n    </tr>\n    <tr>\n      <th>7873</th>\n      <td>This \"movie\" and I say this lightly, is nothing but pure trash. I feel sorry for those people that actually wasted their money to go see this in theaters..I saw a screener of the movie from a friend and I've regretted it ever since. &lt;br /&gt;&lt;br /&gt;As a black woman, I am EXTREMELY embarrassed to have seen this. More so, I am extremely horrified that people of other races may have seen this as well...</td>\n      <td>1</td>\n      <td>[negative]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"buildModel\"></a>\n## 4. Model Building"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"trainWorkflow\"></a>\n## 4.A Train the sentiment analysis model using workflow"}, {"metadata": {}, "cell_type": "code", "source": "import os\nfrom watson_nlp.workflows.document_sentiment import BERT\nfrom watson_nlp.toolkit import bert_utils", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Download Pretrained model resource \npretrained_model_resource = watson_nlp.load(watson_nlp.download(\"pretrained-model_bert_multi_bert_multi_uncased\"))\n# Print the number of hidden layers\nbert_config = bert_utils.BertConfig.from_json_file(pretrained_model_resource.bert_config_path)\nprint(\"num_hidden_layers in base model: {}\".format(bert_config.num_hidden_layers))", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "num_hidden_layers in base model: 12\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "There are 12 layers in the `pretrained-model_bert_multi_bert_multi_uncased` model. You can modify the number of layers and other hyperparameters as shown in the next cells"}, {"metadata": {}, "cell_type": "code", "source": "# Load the Sentiment workflow model for English\nsentiment_model = watson_nlp.download_and_load('sentiment-aggregated_cnn-workflow_en_stock')", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Download relevant stock models\nprint('Downloading Syntax')\nsyntax_model = watson_nlp.load(watson_nlp.download('syntax_izumo_en_stock'))", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "Downloading Syntax\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "syntax_lang_code_map = {\"en\": syntax_model}", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<div class=\"alert alert-block alert-warning\">\n<b>Warning!</b></div>\n<span style=\"color:red\">The next cell is going to take a lot of time in training. You can reduce this argument `train_max_seq_length` to 32 or 64 for quicker training</span>"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Training hyperparameters & arguments:\n\n- train_file: Name of the json file which will be used for training the model\n- test_file: Name of the json file which will be used for evaluating the model\n- syntax_lang_code_map: A dictionary with language and syntax model. `{\"en\": syntax_model}` in this case\n- pretrained_model_resource: The name of the pretrained model downloaded from Watson NLP library. `pretrained-model_bert_multi_bert_multi_uncased` in this case.\n- label_list: List of labels for sentiment classification. `['negative', 'neutral', 'positive']`\n- learning_rate: [Learning rate for the model](https://en.wikipedia.org/wiki/Learning_rate). `2e-5`\n- num_train_epochs: Number of times the learning algorithm will work through the entire training dataset. `5`\n- do_lower_case: Convert all text to lower case. `True`\n- train_max_seq_length: Maximum number of tokens that a training sequence can contain. `128`\n- train_batch_size: Training batch size. `32`\n- dev_batch_size: Validation batch size. `32`\n- predict_batch_size: Test batch size. `128`\n- predict_max_seq_length: Maximum number of tokens that a prediction sequence can contain. `64`\n- num_layers_to_remove: Number of layers to be removed from the base model. `2`\n- combine_approach: \"Mean\" will average score calculation directly while 'NON_NEUTRAL_MEAN' will ignore neutral sentences for average score calculation. `NON_NEUTRAL_MEAN`\n- keep_model_artifacts: Keep model artifacts. `True`"}, {"metadata": {}, "cell_type": "code", "source": "# Train using the workflow with compression \n# Set number of layers to remove as 2\nbert_wkflow = BERT.train(\n              train_file,\n              test_file,\n              syntax_lang_code_map,\n              pretrained_model_resource,\n              label_list=['negative', 'neutral', 'positive'],\n              learning_rate=2e-5,\n              num_train_epochs=5,\n              do_lower_case=True,\n              train_max_seq_length=128,\n              train_batch_size=32,\n              dev_batch_size=32,\n              predict_batch_size=128,\n              predict_max_seq_length=128,\n              num_layers_to_remove=2,\n              combine_approach=\"NON_NEUTRAL_MEAN\",\n              keep_model_artifacts=True)", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "Epoch 1/5\n250/250 - 9830s - loss: 17.1058 - test_accuracy: 0.7315 - val_loss: 10.7383 - val_test_accuracy: 0.8596 - 9830s/epoch - 39s/step\nEpoch 2/5\n250/250 - 9798s - loss: 7.8892 - test_accuracy: 0.9055 - val_loss: 9.9122 - val_test_accuracy: 0.8844 - 9798s/epoch - 39s/step\nEpoch 3/5\n250/250 - 9787s - loss: 4.9006 - test_accuracy: 0.9486 - val_loss: 10.9308 - val_test_accuracy: 0.9107 - 9787s/epoch - 39s/step\nEpoch 4/5\n250/250 - 9782s - loss: 2.9824 - test_accuracy: 0.9725 - val_loss: 14.7547 - val_test_accuracy: 0.9048 - 9782s/epoch - 39s/step\nEpoch 5/5\n250/250 - 9778s - loss: 2.1926 - test_accuracy: 0.9840 - val_loss: 17.0539 - val_test_accuracy: 0.9038 - 9778s/epoch - 39s/step\n", "name": "stdout"}, {"output_type": "stream", "text": "./build/lib/watson_nlp/blocks/document_sentiment/bert/bert.py:456: DeprecationWarning: Call to deprecated class BERT. (BERT Document Sentiment Class is deprecated. Please use watson_nlp.blocks.sentiment.sentence_sentiment_bert.SentenceSentimentBERT instead.) -- Deprecated since version 3.X.X.\n./build/lib/watson_nlp/workflows/document_sentiment/bert.py:385: DeprecationWarning: Call to deprecated class BERT. (BERT Document Sentiment Workflow is deprecated. Please use watson_nlp.workflows.sentiment.aggregated_workflow.AggregatedSentiment instead.) -- Deprecated since version 3.X.X.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "# BERT config has been updated and saved in pre_train artifacts\"\nbert_updated_config_path = \"bert_pretrain_artifact/bert_config.json\"\nbert_config_updated  = bert_utils.BertConfig.from_json_file(bert_updated_config_path)\nprint(\"num_hidden_layers after compression: {}\".format(bert_config_updated.num_hidden_layers))", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "num_hidden_layers after compression: 10\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "You can observe here that the number of layers after compression has reduced from 12 to 10 i.e 2 layers were reduced from the base model for faster training."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"saveModel\"></a>\n## 4.B Save the workflow/model"}, {"metadata": {}, "cell_type": "code", "source": "# Save the Workflow in a given location\nmodel_path = 'bert_set/wkflow'\nbert_wkflow.save('bert_set/wkflow')", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "WARNING:absl:Found untraced functions such as word_embeddings_layer_call_fn, word_embeddings_layer_call_and_return_conditional_losses, embedding_postprocessor_layer_call_fn, embedding_postprocessor_layer_call_and_return_conditional_losses, encoder_layer_call_fn while saving (showing 5 of 680). These functions will not be directly callable after loading.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fe0d163b1c0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fe0d159fc40> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fe0d155ecd0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fe0d151ad90> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fe0d14daf40> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fe0d149bdc0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fe0d145fee0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fe0d1421fd0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fe0d13eb1f0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<watson_nlp.toolkit.bert_utils.model.Attention object at 0x7fe0d13ab280> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'watson_nlp.toolkit.bert_utils.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n", "name": "stderr"}]}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "# Load the saved workflow for predict\nwk_loaded = watson_nlp.load(model_path)", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "./build/lib/watson_nlp/blocks/document_sentiment/bert/bert.py:162: DeprecationWarning: Call to deprecated class BERT. (BERT Document Sentiment Class is deprecated. Please use watson_nlp.blocks.sentiment.sentence_sentiment_bert.SentenceSentimentBERT instead.) -- Deprecated since version 3.X.X.\n./build/lib/watson_nlp/workflows/document_sentiment/bert.py:216: DeprecationWarning: Call to deprecated class BERT. (BERT Document Sentiment Workflow is deprecated. Please use watson_nlp.workflows.sentiment.aggregated_workflow.AggregatedSentiment instead.) -- Deprecated since version 3.X.X.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "# Run the workflow with input as raw document and language code\nraw_document = 'I have been looking for this film for ages because it is quite rare to find as it was one of the video nasties. I finally found it on DVD at the end of last year it is a very low budget movie The story is set around amazon jungle tribes that are living in fear of the devil. Laura Crawford is a model who is kidnapped by a gang of thugs while she is working in South America. They take her into the jungle Laura is guarded by some ridiculous native who calls himself \"The Devil\" she has to go though all unpleasant things until they are happy. Maidens are Chained up. The devil demonstrates eating flesh in a horrible manner. Peter Weston, is the devil hunter, who goes into the jungle to try and rescue her,'\nsentiment = wk_loaded.run(raw_document, language_code=\"en\")\nsentiment", "execution_count": 19, "outputs": [{"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "{\n  \"score\": 0.364364,\n  \"label\": \"SENT_POSITIVE\",\n  \"mixed\": true,\n  \"target\": \"\",\n  \"sentiment_mentions\": [],\n  \"producer_id\": {\n    \"name\": \"Document BERT Sentiment\",\n    \"version\": \"0.0.1\"\n  }\n}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Save the model on the Cloud Object Storage (COS) associated with the Watson Studio instance"}, {"metadata": {}, "cell_type": "code", "source": "#project.save_data('bert_wkflow_imdb_5_epochs', data=bert_wkflow.as_file_like_object(), overwrite=True)", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"evaluateModel\"></a>\n## 5. Model Evaluation"}, {"metadata": {}, "cell_type": "markdown", "source": "Helper functions to extract text from the dataset and create a new dataframe with the corresponding sentiment"}, {"metadata": {}, "cell_type": "code", "source": "def extract_sentiment(review_text):\n    # run the syntax model\n    syntax_result = syntax_model.run(review_text, parsers=('token', 'lemma', 'part_of_speech'))\n    sentiment_result = wk_loaded.run(review_text, sentence_sentiment=True, language_code=\"en\")\n    \n    document_sentiment = sentiment_result.to_dict()['label']\n    return document_sentiment\n\n# Helper method to create a new dataframe with the corresponding sentiment\ndef create_sentiment_dataframe(df):\n    sentiment = df['text'].apply(lambda text: extract_sentiment(text))\n    sentiment_df = pd.DataFrame()\n    sentiment_df['Document Sentiment'] = sentiment\n    return sentiment_df", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "test_small = test_orig", "execution_count": 22, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "sentiment_df = create_sentiment_dataframe(test_small)\nmovies_sentiment_df = test_small[['text', 'labels']].merge(sentiment_df[['Document Sentiment']], how='left', left_index=True, right_index=True)\nmovies_sentiment_df.head()", "execution_count": 23, "outputs": [{"output_type": "execute_result", "execution_count": 23, "data": {"text/plain": "                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n2828  This film has nothing whatever to do with the Sphinx, and the title is just a come-on. The story concerns an imagined true and concealed tomb in the Valley of the Kings, of King Seti I, second pharaoh of the 19th Dynasty, New Kingdom period. It is not a bad yarn, and a great deal of the film is shot on location. Even the scenes in the Winter Palace Hotel lobby in Luxor were really shot there, ...   \n8360  I went to see this movie at our college theater thirty years ago because I liked Bruce Dern in Silent Running and Family Plot. To this day (sorry Jack Nicholson), it is still the dullest movie I've ever seen. It just went on and on with no discernible point and then - it just ended. The lights came up and I watched everyone looking around in confusion. Had the projectionist missed a reel? I've...   \n3369  Whether this movie is propaganda or not (I firmly believe it is not), it really shows the power of Media. The importance of this documentary is not to show how good of a man Chavez is. It is really to demonstrate the way the Bolivarians saw how it happened, the Chavez way of seeing it. Although it may seem wrong and bias to support a film , I think the point of view shown in the movie is utter...   \n4821  Larry Clark is not renowned for his talents as a writer or a director, but he has made some undeniably important films. Kids, Bully, and to a lesser extent Ken Park all achieve their intended purpose: shock, revulsion, and even disgust. These films are uncompromising in their content and use their controversial nature to expose very serious problems in modern youth. Kids exposed us to the prol...   \n9840  I just saw DreamGirls yesterday, and I was REALLY underimpressed. Despite all the Oscar buzz, this is nothing special. Anyone who was really impressed by this film has never bothered to see any of the true movie musical classics. Except for Eddie Murphy's great musical and dramatic performance, Dreamgirls is just a glorified TV movie with no style or flair. Just a bunch of amateurs singing AT ...   \n\n      labels Document Sentiment  \n2828       0      SENT_NEGATIVE  \n8360       0      SENT_NEGATIVE  \n3369       1      SENT_POSITIVE  \n4821       0      SENT_NEGATIVE  \n9840       0      SENT_NEGATIVE  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n      <th>Document Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2828</th>\n      <td>This film has nothing whatever to do with the Sphinx, and the title is just a come-on. The story concerns an imagined true and concealed tomb in the Valley of the Kings, of King Seti I, second pharaoh of the 19th Dynasty, New Kingdom period. It is not a bad yarn, and a great deal of the film is shot on location. Even the scenes in the Winter Palace Hotel lobby in Luxor were really shot there, ...</td>\n      <td>0</td>\n      <td>SENT_NEGATIVE</td>\n    </tr>\n    <tr>\n      <th>8360</th>\n      <td>I went to see this movie at our college theater thirty years ago because I liked Bruce Dern in Silent Running and Family Plot. To this day (sorry Jack Nicholson), it is still the dullest movie I've ever seen. It just went on and on with no discernible point and then - it just ended. The lights came up and I watched everyone looking around in confusion. Had the projectionist missed a reel? I've...</td>\n      <td>0</td>\n      <td>SENT_NEGATIVE</td>\n    </tr>\n    <tr>\n      <th>3369</th>\n      <td>Whether this movie is propaganda or not (I firmly believe it is not), it really shows the power of Media. The importance of this documentary is not to show how good of a man Chavez is. It is really to demonstrate the way the Bolivarians saw how it happened, the Chavez way of seeing it. Although it may seem wrong and bias to support a film , I think the point of view shown in the movie is utter...</td>\n      <td>1</td>\n      <td>SENT_POSITIVE</td>\n    </tr>\n    <tr>\n      <th>4821</th>\n      <td>Larry Clark is not renowned for his talents as a writer or a director, but he has made some undeniably important films. Kids, Bully, and to a lesser extent Ken Park all achieve their intended purpose: shock, revulsion, and even disgust. These films are uncompromising in their content and use their controversial nature to expose very serious problems in modern youth. Kids exposed us to the prol...</td>\n      <td>0</td>\n      <td>SENT_NEGATIVE</td>\n    </tr>\n    <tr>\n      <th>9840</th>\n      <td>I just saw DreamGirls yesterday, and I was REALLY underimpressed. Despite all the Oscar buzz, this is nothing special. Anyone who was really impressed by this film has never bothered to see any of the true movie musical classics. Except for Eddie Murphy's great musical and dramatic performance, Dreamgirls is just a glorified TV movie with no style or flair. Just a bunch of amateurs singing AT ...</td>\n      <td>0</td>\n      <td>SENT_NEGATIVE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Using custom function to calculate accuracy. **Note**: model evaluation method is WIP for the workflow based model and will be released soon after which you will not need to write custom code for evaluation."}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\nconditions = [\n    movies_sentiment_df['labels'].eq(0) & movies_sentiment_df['Document Sentiment'].eq('SENT_NEGATIVE'),\n    movies_sentiment_df['labels'].eq(1) & movies_sentiment_df['Document Sentiment'].eq('SENT_POSITIVE'),\n]\n\nchoices = [1,1]\n\nmovies_sentiment_df['score'] = np.select(conditions, choices, default=0)", "execution_count": 24, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(\"ACCURACY SCORE:\", movies_sentiment_df['score'].sum()/len(movies_sentiment_df['score']))", "execution_count": 25, "outputs": [{"output_type": "stream", "text": "ACCURACY SCORE: 0.8855\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Confusion Matrix"}, {"metadata": {}, "cell_type": "code", "source": "# confusion matrix in sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\n# actual values\nmovies_sentiment_df['labels'] = movies_sentiment_df['labels'].replace({0:'SENT_NEGATIVE', 1:'SENT_POSITIVE'})\nactual = movies_sentiment_df['labels']\n# predicted values\npredicted = movies_sentiment_df['Document Sentiment']\n\n# confusion matrix\nmatrix = confusion_matrix(actual,predicted, labels=['SENT_POSITIVE','SENT_NEGATIVE'])\nprint('Confusion matrix : \\n',matrix)\n\n# outcome values order in sklearn\ntp, fn, fp, tn = confusion_matrix(actual,predicted,labels=['SENT_POSITIVE','SENT_NEGATIVE']).reshape(-1)\nprint('Outcome values : \\n', tp, fn, fp, tn)\n\n# classification report for precision, recall f1-score and accuracy\nmatrix = classification_report(actual,predicted,labels=['SENT_POSITIVE','SENT_NEGATIVE'])\nprint('Classification report : \\n',matrix)", "execution_count": 26, "outputs": [{"output_type": "stream", "text": "Confusion matrix : \n [[837 167]\n [ 62 934]]\nOutcome values : \n 837 167 62 934\nClassification report : \n                precision    recall  f1-score   support\n\nSENT_POSITIVE       0.93      0.83      0.88      1004\nSENT_NEGATIVE       0.85      0.94      0.89       996\n\n     accuracy                           0.89      2000\n    macro avg       0.89      0.89      0.89      2000\n weighted avg       0.89      0.89      0.89      2000\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"summary\"></a>\n## 6. Summary"}, {"metadata": {}, "cell_type": "markdown", "source": "<span style=\"color:blue\">This notebook demonstrates how to fine-tune/re-train the BERT Sentiment workflow using compression. The model performance has improved over Out-of-the-box (OOTB) pre-trained model where accuracy was 87% and which is now 96% with the fine-tuned model. The model performance generally improves especially if you have nuances in the dataset that your model needs to learn from the dataset.</span>\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Please note that this content is made available by IBM Build Lab to foster Embedded AI technology adoption. The content may include systems & methods pending patent with USPTO and protected under US Patent Laws. For redistribution of this content, IBM will use release process. For any questions please log an issue in the hosting [GitHub repository](https://github.com/ibm-ecosystem-engineering/Watson-NLP). \n\nDeveloped by IBM Build Lab \n\nCopyright - 2022 IBM Corporation"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}