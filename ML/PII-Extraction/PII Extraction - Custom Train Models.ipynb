{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Custom Train Models for PII Etraction using Watson NLP"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Use Case\n","\n","\n","This notebook demonstrates how to train PII extraction models using Watson NLP. The goal of PII extraction is to automatically identify and classify specific PII entities , such as Educational details, Employee ID, Salary and more.\n","\n","\n","## What you'll learn in this notebook\n","\n","Watson NLP implements state-of-the-art classification algorithms from three different families: \n","- Classic machine learning using CRF (Conditional Random Field)\n","- Deep learning using BiLSTM (Bidirectional Long Short Term Memory)\n","\n","In this notebook, you'll learn how to:\n","\n","- **Prepare your data** so that it can be used as training data for the Watson NLP classification algorithms.\n","- **Train a custom CRF model** using `watson_nlp.workflows.entity_mentions.SIRE`.\n","- **Train a BiLSTM** using `watson_nlp.blocks.entity_mentions.BiLSTM`.\n","- **Store and load models** as an asset of a Watson Studio project.\n","\n","## Table of Contents\n","\n","1. [Before You Start](#beforeYouStart)\n","1.  [Prepare Training](#prepareTraining)\n","1.  [Model Building](#buildModel)\n","    1. [SIRE Training](#sire)\n","    1. [BiLSTM Training](#bilstm)\n","1.  [Summary](#summary)"]},{"cell_type":"markdown","metadata":{},"source":["##### <a id=\"beforeYouStart\"></a>\n","## 1. Before You Start\n","\n","<div class=\"alert alert-block alert-danger\">\n","<b>Stop kernel of other notebooks.</b></div>\n","\n","**Note:** If you have other notebooks currently running with the _Default Python 3.x environment, **stop their kernels** before running this notebook. All these notebooks share the same runtime environment, and if they are running in parallel, you may encounter memory issues. To stop the kernel of another notebook, open that notebook, and select _File > Stop Kernel_.\n","\n","<div class=\"alert alert-block alert-warning\">\n","<b>Set Project token.</b></div>\n","\n","Before you can begin working on this notebook in Watson Studio in Cloud Pak for Data as a Service, you need to ensure that the project token is set so that you can access the project assets via the notebook.\n","\n","When this notebook is added to the project, a project access token should be inserted at the top of the notebook in a code cell. If you do not see the cell above, add the token to the notebook by clicking **More > Insert project token** from the notebook action bar.  By running the inserted hidden code cell, a project object is created that you can use to access project resources.\n","\n","![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n","\n","<div class=\"alert alert-block alert-info\">\n","<b>Tip:</b> Cell execution</div>\n","\n","Note that you can step through the notebook execution cell by cell, by selecting Shift-Enter. Or you can execute the entire notebook by selecting **Cell -> Run All** from the menu."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: faker in /opt/conda/envs/Python-3.10-CUDA/lib/python3.10/site-packages (17.0.0)\r\n","Requirement already satisfied: python-dateutil>=2.4 in /opt/conda/envs/Python-3.10-CUDA/lib/python3.10/site-packages (from faker) (2.8.2)\r\n","Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.10-CUDA/lib/python3.10/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\r\n"]}],"source":["!pip install faker"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import json\n","import pandas as pd\n","import watson_nlp\n","from faker import Faker\n","import random\n","import string\n","from watson_nlp import data_model as dm\n","from watson_nlp.toolkit.entity_mentions_utils import prepare_train_from_json, create_iob_labels"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Silence Tensorflow warnings\n","import tensorflow as tf\n","tf.get_logger().setLevel('ERROR')\n","tf.autograph.set_verbosity(0)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Load a syntax model to split the text into sentences and tokens\n","syntax_model = watson_nlp.load(watson_nlp.download('syntax_izumo_en_stock'))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"prepareTraining\"></a>\n","## 2. Preparing Training Data"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["#Generate the dataset using faker\n","fake = Faker(locale='en_US')\n","\n","def format_data():\n","    # Generate a random degree level\n","    degree_level = fake.random_element(elements=('Bachelor\\'s', 'Master\\'s', 'Doctorate'))\n","\n","    # Generate a random field of study\n","    field_of_study = fake.random_element(elements=('Computer Science', 'Engineering', 'Business', 'Psychology','Medical'))\n","\n","\n","    # Generate a random prefix with 1-2 alphabets\n","    prefix = ''.join(random.choices(string.ascii_uppercase, k=random.randint(1, 2)))\n","    # Generate a random employee ID with the prefix and a random integer\n","    employee_id = f\"{prefix}{fake.random_int(min=10000, max=99999):05d}\"\n","\n","    # Generate salary using faker\n","    salary = str(fake.pyfloat(left_digits=5, right_digits=2, positive=True, min_value=1000, max_value=5000))\n","    \n","    \n","    \n","    text_1 = \"I studied %s in %s, My employee id is %s and salary is %s\" %(degree_level,field_of_study,employee_id,salary)\n","    text_2 = \" Hello, My employee id is %s and I done my %s in %s, I am earning %s per month\" %(employee_id,degree_level, field_of_study,salary)\n","    text_3 = \"My monthly Earning is %s and employee code is %s, I studied %s in %s\" %(salary,employee_id,degree_level,field_of_study)\n","    text = random.choice([text_1, text_2,text_3])\n","    \n","    \n","    field_of_study_begin = text.find(field_of_study)\n","    field_of_study_end = field_of_study_begin + len(field_of_study)\n","\n","    degree_level_begin = text.find(degree_level)\n","    degree_level_end = degree_level_begin + len(degree_level)\n","  \n","    employee_id_begin = text.find(employee_id)\n","    employee_id_end = employee_id_begin + len(employee_id)\n","\n","    salary_begin = text.find(salary)\n","    salary_end = salary_begin + len(salary)\n","    \n","    \n","    data = {\n","                \"text\": text,\n","                \"mentions\": [\n","                    {\n","                        \"location\": {\n","                            \"begin\": field_of_study_begin,\n","                            \"end\": field_of_study_end\n","                        },\n","                        \"text\": field_of_study,\n","                        \"type\": \"field_of_study\"\n","                    },\n","                    {\n","                        \"location\": {\n","                            \"begin\": degree_level_begin,\n","                            \"end\": degree_level_end\n","                        },\n","                        \"text\": degree_level,\n","                        \"type\": \"degree_level\"\n","                    },\n","                                        {\n","                        \"location\": {\n","                            \"begin\": employee_id_begin,\n","                            \"end\": employee_id_end\n","                        },\n","                        \"text\": employee_id,\n","                        \"type\": \"employee_id\"\n","                    },\n","                    {\n","                        \"location\": {\n","                            \"begin\": salary_begin,\n","                            \"end\": salary_end\n","                        },\n","                        \"text\": salary,\n","                        \"type\": \"salary\"\n","                    }\n","                ]   \n","            }\n","    \n","    return data"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["{'text': \"My monthly Earning is 4463.7 and employee code is T43358, I studied Master's in Business\",\n"," 'mentions': [{'location': {'begin': 80, 'end': 88},\n","   'text': 'Business',\n","   'type': 'field_of_study'},\n","  {'location': {'begin': 68, 'end': 76},\n","   'text': \"Master's\",\n","   'type': 'degree_level'},\n","  {'location': {'begin': 50, 'end': 56},\n","   'text': 'T43358',\n","   'type': 'employee_id'},\n","  {'location': {'begin': 22, 'end': 28}, 'text': '4463.7', 'type': 'salary'}]}"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["#Sample dataset\n","format_data()"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"data":{"text/plain":["{'file_name': 'faker_PII_text_train.json',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': 'e952dfbd-f642-4712-b7a5-deae8425af2a'}"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["#Prepared and store Training dataset for Driving License dataset\n","train_list_faker = []\n","for i in range(0, 30000):\n","    train_list_faker.append(format_data())\n","\n","with open('faker_PII_text_train.json', 'w') as f:\n","    json.dump(train_list_faker, f)\n","project.save_data('faker_PII_text_train.json', data=json.dumps(train_list_faker), overwrite=True)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"data":{"text/plain":["{'file_name': 'faker_PII_text_test.json',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': '0059c8e9-2566-4288-a1c2-092dc29d418e'}"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["#Prepared and store Training dataset for Driving License dataset\n","test_list_faker = []\n","for i in range(0, 1000):\n","    test_list_faker.append(format_data())\n","\n","with open('faker_PII_text_test.json', 'w') as f:\n","    json.dump(test_list_faker, f)\n","project.save_data('faker_PII_text_test.json', data=json.dumps(test_list_faker), overwrite=True)"]},{"cell_type":"markdown","metadata":{},"source":["Since the data is already formatted correctly, the following process is needed to read the JSON data files from Watson Studio project assets and save them to the runtime working directory where they will be used as input for training the models."]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["train_data = dm.DataStream.from_json_array(\"faker_PII_text_train.json\")\n","train_iob_stream = prepare_train_from_json(train_data, syntax_model)\n","dev_data = dm.DataStream.from_json_array(\"faker_PII_text_test.json\")\n","dev_iob_stream = prepare_train_from_json(dev_data, syntax_model)"]},{"cell_type":"markdown","metadata":{},"source":["The text inputs will be converted into a streaming array where the text is broken down by the syntax model."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"buildModel\"></a>\n","## 3. Model Building\n","\n","Entity extraction uses the entity-mentions block to encapsulate algorithms for the task of extracting mentions of entities (person, organizations, dates, locations,...) from the input text. The blocks and workflows offer implementations of strong entity extraction algorithms from each of the four families: rule-based, classic ML, deep-learning and transformers."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"sire\"></a>\n","### 3.1 SIRE Training"]},{"cell_type":"markdown","metadata":{},"source":["You can train SIRE models using either CRF & Maximum Entropy template as base models. Between the two, CRF based template takes longer to train but gives better results.\n","\n","These algorithms accept a set of featured in the form of dictionaries and regular expressions. A set of predefined feature extractors are provided for multiple languages, and you can also define your own features."]},{"cell_type":"code","execution_count":3,"metadata":{"scrolled":true},"outputs":[],"source":["#help(watson_nlp.workflows.entity_mentions.SIRE)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# Download the algorithm template\n","mentions_train_template = watson_nlp.load(watson_nlp.download('file_path_entity-mentions_sire_multi_template-crf'))\n","# Download the feature extractor\n","default_feature_extractor = watson_nlp.load(watson_nlp.download('feature-extractor_rbr_entity-mentions_sire_en_stock'))"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Initializing viterbi classifier\n","\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n","\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n","Get Feature str 818099\n","Done get feature str 818099\n","done. [51\u001b[33mg\u001b[0m573\u001b[33mm\u001b[0m340\u001b[33mk\u001b[0m,8\u001b[33mg\u001b[0m985\u001b[33mm\u001b[0m520\u001b[33mk\u001b[0m]\n","gramSize = 2\n","number of processes: 5\n","Initial processing:  (# of words: 265660, # of sentences: 20000)\n","senIndex[1] = 7222, wordIndex = 53136\n","senIndex[2] = 11699, wordIndex = 106285\n","senIndex[3] = 14474, wordIndex = 159406\n","senIndex[4] = 17249, wordIndex = 212535\n","senIndex[5] = 19999, wordIndex = 265660\n","\u001b[32m[ME_CRF::scaleModel]\u001b[0m Updater -- l1=\u001b[32m0.1\u001b[0m, l2=\u001b[32m0.005\u001b[0m, history size=\u001b[32m5\u001b[0m, progress windows size \u001b[32m20\u001b[0m\n"," Iteration           Obj             WErr                         Timing       %Eff        Per thread timing\n","               543176.67      6.63/ 63.18             E:1.08 s, M:0.08 s.       1.00 [m:1.04, M:1.07, av:1.06]\n","         0   240271.27     18.58/ 73.16             E:1.08 s, M:0.08 s.       1.00 [m:1.04, M:1.08, av:1.07]\n","         1    54373.36      6.02/ 50.00             E:1.10 s, M:0.09 s.       1.00 [m:1.07, M:1.09, av:1.09]\n","         2    25039.31      0.00/  0.00             E:1.06 s, M:0.10 s.       1.00 [m:1.02, M:1.06, av:1.05]\n","         3    11123.39      0.00/  0.00             E:1.07 s, M:0.10 s.       1.00 [m:1.03, M:1.06, av:1.06]\n","         4     5926.82      0.00/  0.00             E:1.06 s, M:0.12 s.       1.00 [m:1.02, M:1.05, av:1.05]\n","         5     3692.24      0.00/  0.00             E:1.06 s, M:0.11 s.       1.00 [m:1.02, M:1.06, av:1.03]\n","         6     2746.32      0.00/  0.00             E:1.07 s, M:0.11 s.       1.00 [m:1.02, M:1.06, av:1.06]\n","         7     1449.70      0.00/  0.00             E:1.05 s, M:0.11 s.       1.00 [m:1.02, M:1.04, av:1.03]\n","         8      990.55      0.00/  0.00             E:1.07 s, M:0.10 s.       1.00 [m:1.02, M:1.06, av:1.05]\n","         9      823.03      0.00/  0.00             E:1.06 s, M:0.10 s.       1.00 [m:1.02, M:1.05, av:1.05]\n","        10      674.95      0.00/  0.00             E:1.05 s, M:0.10 s.       1.00 [m:1.01, M:1.04, av:1.04]\n","        11      551.34      0.00/  0.00             E:1.04 s, M:0.10 s.       1.00 [m:1.02, M:1.03, av:1.03]\n","        12      413.89      0.00/  0.00             E:1.07 s, M:0.10 s.       1.00 [m:1.03, M:1.06, av:1.06]\n","        13      234.79      0.00/  0.00             E:1.06 s, M:0.10 s.       1.00 [m:1.02, M:1.05, av:1.03]\n","        14      140.28      0.00/  0.00             E:1.07 s, M:0.12 s.       1.00 [m:1.02, M:1.05, av:1.04]\n","        15      110.84      0.00/  0.00             E:1.09 s, M:0.11 s.       1.00 [m:1.07, M:1.09, av:1.08]\n","        16      100.09      0.00/  0.00             E:1.07 s, M:0.10 s.       1.00 [m:1.03, M:1.06, av:1.06]\n","        17       87.69      0.00/  0.00             E:1.06 s, M:0.10 s.       1.00 [m:1.01, M:1.05, av:1.04]\n","        18       76.74      0.00/  0.00             E:1.05 s, M:0.10 s.       1.00 [m:1.00, M:1.04, av:1.04]\n","        19       61.49      0.00/  0.00             E:1.09 s, M:0.11 s.       1.00 [m:1.05, M:1.08, av:1.08]\n","Not enough progress in the last 5 iters.. converged.\n","    Thread     Total      Wait Effective      %Eff         #Sents/sec\n","         0     21.99      0.01     21.98      1.00             3829.21\n","         1     21.80      0.03     21.77      1.00             3872.01\n","         2     21.81      0.01     21.80      1.00             3850.97\n","         3     21.86      0.03     21.84      1.00             3818.95\n","         4     21.95      0.02     21.93      1.00             3822.87\n","Parent: the end!\n","Initializing viterbi classifier\n","\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n","\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n"]}],"source":["# Train the model\n","sire_custom = watson_nlp.workflows.entity_mentions.SIRE.train(syntax_model=syntax_model,\n","                                                              labeled_entity_mentions='/home/wsuser/work/', \n","                                                              #labeled_entity_mentions=train_data,\n","                                                              model_language='en', \n","                                                              template_resource=mentions_train_template, \n","                                                              feature_extractors=[default_feature_extractor], \n","                                                              l1=0.1, \n","                                                              l2=0.005, \n","                                                              num_epochs=50, \n","                                                              num_workers=5)"]},{"cell_type":"markdown","metadata":{},"source":["The following code will save the custom model to Watson Studio by using the project library."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Saved 9722 features.\n"]},{"data":{"text/plain":["{'file_name': 'PII_sire_custom',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': '0941d329-e971-45c2-b766-082fe06434a4'}"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# Save the model\n","project.save_data('PII_sire_custom', data=sire_custom.as_file_like_object(), overwrite=True)"]},{"cell_type":"markdown","metadata":{},"source":["Let's run the model on one example input from the dev dataset."]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/plain":["\" Hello, My employee id is MN34275 and I done my Master's in Medical, I am earning 3362.18 per month\""]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["text = pd.read_json('faker_PII_text_test.json')['text'][1]\n","text"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"text/plain":["{\n","  \"mentions\": [\n","    {\n","      \"span\": {\n","        \"begin\": 26,\n","        \"end\": 33,\n","        \"text\": \"MN34275\"\n","      },\n","      \"type\": \"employee_id\",\n","      \"producer_id\": null,\n","      \"confidence\": 0.999635088942728,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 48,\n","        \"end\": 56,\n","        \"text\": \"Master's\"\n","      },\n","      \"type\": \"degree_level\",\n","      \"producer_id\": null,\n","      \"confidence\": 0.9996819393489853,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 60,\n","        \"end\": 67,\n","        \"text\": \"Medical\"\n","      },\n","      \"type\": \"field_of_study\",\n","      \"producer_id\": null,\n","      \"confidence\": 0.9999710541077216,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 82,\n","        \"end\": 89,\n","        \"text\": \"3362.18\"\n","      },\n","      \"type\": \"salary\",\n","      \"producer_id\": null,\n","      \"confidence\": 0.9987221851024309,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    }\n","  ],\n","  \"producer_id\": {\n","    \"name\": \"Entity-Mentions SIRE Workflow\",\n","    \"version\": \"0.0.1\"\n","  }\n","}"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["# Run the model\n","sire_result = sire_custom.run(text)\n","sire_result"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"bilstm\"></a>\n","### 3.2 BiLSTM Training"]},{"cell_type":"markdown","metadata":{},"source":["The deep-learning algorithm used in this block performs sequence labelling based on the BiLSTM architecture followed by a CRF layer. It uses GloVe embeddings as features."]},{"cell_type":"code","execution_count":4,"metadata":{"scrolled":true},"outputs":[],"source":["#help(watson_nlp.blocks.entity_mentions.BiLSTM)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# Download the GloVe model to be used as embeddings in the BiLSTM\n","glove_model = watson_nlp.load(watson_nlp.download('embedding_glove_en_stock'))"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["313/313 [==============================] - 16s 52ms/step - loss: 0.1633 - val_loss: 0.0067\n","313/313 [==============================] - 9s 28ms/step - loss: 0.0059 - val_loss: 0.0022\n","313/313 [==============================] - 9s 28ms/step - loss: 0.0026 - val_loss: 0.0011\n","313/313 [==============================] - 9s 27ms/step - loss: 0.0015 - val_loss: 6.8084e-04\n","313/313 [==============================] - 9s 27ms/step - loss: 9.7924e-04 - val_loss: 4.5391e-04\n","313/313 [==============================] - 9s 28ms/step - loss: 6.9356e-04 - val_loss: 3.2081e-04\n","313/313 [==============================] - 9s 27ms/step - loss: 5.1217e-04 - val_loss: 2.3624e-04\n","313/313 [==============================] - 8s 27ms/step - loss: 3.9269e-04 - val_loss: 1.7890e-04\n","313/313 [==============================] - 9s 27ms/step - loss: 3.0576e-04 - val_loss: 1.3859e-04\n","313/313 [==============================] - 9s 28ms/step - loss: 2.4473e-04 - val_loss: 1.0903e-04\n","313/313 [==============================] - 9s 28ms/step - loss: 1.9824e-04 - val_loss: 8.6839e-05\n","313/313 [==============================] - 9s 27ms/step - loss: 1.6169e-04 - val_loss: 6.9917e-05\n","313/313 [==============================] - 9s 27ms/step - loss: 1.3323e-04 - val_loss: 5.6704e-05\n","313/313 [==============================] - 8s 27ms/step - loss: 1.1003e-04 - val_loss: 4.6366e-05\n","313/313 [==============================] - 9s 28ms/step - loss: 9.2460e-05 - val_loss: 3.8070e-05\n","313/313 [==============================] - 9s 28ms/step - loss: 7.7216e-05 - val_loss: 3.1404e-05\n","313/313 [==============================] - 9s 28ms/step - loss: 6.4609e-05 - val_loss: 2.6026e-05\n","313/313 [==============================] - 9s 28ms/step - loss: 5.4282e-05 - val_loss: 2.1668e-05\n","313/313 [==============================] - 9s 28ms/step - loss: 4.6498e-05 - val_loss: 1.8025e-05\n","313/313 [==============================] - 9s 28ms/step - loss: 3.9288e-05 - val_loss: 1.5045e-05\n","313/313 [==============================] - 9s 28ms/step - loss: 3.4052e-05 - val_loss: 1.2551e-05\n","313/313 [==============================] - 9s 28ms/step - loss: 2.8603e-05 - val_loss: 1.0495e-05\n","313/313 [==============================] - 9s 28ms/step - loss: 2.4358e-05 - val_loss: 8.7895e-06\n","313/313 [==============================] - 9s 28ms/step - loss: 2.0914e-05 - val_loss: 7.3536e-06\n","313/313 [==============================] - 9s 28ms/step - loss: 1.7804e-05 - val_loss: 6.1611e-06\n","313/313 [==============================] - 9s 28ms/step - loss: 1.5320e-05 - val_loss: 5.1746e-06\n","313/313 [==============================] - 8s 27ms/step - loss: 1.2907e-05 - val_loss: 4.3503e-06\n","313/313 [==============================] - 9s 29ms/step - loss: 1.1255e-05 - val_loss: 3.6506e-06\n","313/313 [==============================] - 9s 27ms/step - loss: 9.5739e-06 - val_loss: 3.0619e-06\n","313/313 [==============================] - 9s 27ms/step - loss: 8.2585e-06 - val_loss: 2.5681e-06\n"]}],"source":["# Train BILSTM Model for Educational details entity\n","bilstm_custom = watson_nlp.blocks.entity_mentions.BiLSTM.train(train_iob_stream,\n","                                                              dev_iob_stream,\n","                                                              glove_model.embedding,\n","                                                              num_train_epochs=5)"]},{"cell_type":"markdown","metadata":{},"source":["The following code will save the custom model to Watson Studio by using the project library."]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["{'file_name': 'PII_bilstm_custom',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': 'f82985ac-5595-40bd-be49-2f6d3d87b1a1'}"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["# Save the model\n","project.save_data('PII_bilstm_custom', data=bilstm_custom.as_file_like_object(), overwrite=True)"]},{"cell_type":"markdown","metadata":{},"source":["Let's run the model on one example input."]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/plain":["{\n","  \"mentions\": [\n","    {\n","      \"span\": {\n","        \"begin\": 26,\n","        \"end\": 33,\n","        \"text\": \"MN34275\"\n","      },\n","      \"type\": \"employee_id\",\n","      \"producer_id\": {\n","        \"name\": \"BiLSTM Entity Mentions\",\n","        \"version\": \"1.0.0\"\n","      },\n","      \"confidence\": 0.9999963045120239,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 48,\n","        \"end\": 56,\n","        \"text\": \"Master's\"\n","      },\n","      \"type\": \"degree_level\",\n","      \"producer_id\": {\n","        \"name\": \"BiLSTM Entity Mentions\",\n","        \"version\": \"1.0.0\"\n","      },\n","      \"confidence\": 0.9999946355819702,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 60,\n","        \"end\": 67,\n","        \"text\": \"Medical\"\n","      },\n","      \"type\": \"field_of_study\",\n","      \"producer_id\": {\n","        \"name\": \"BiLSTM Entity Mentions\",\n","        \"version\": \"1.0.0\"\n","      },\n","      \"confidence\": 0.9999984502792358,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 82,\n","        \"end\": 89,\n","        \"text\": \"3362.18\"\n","      },\n","      \"type\": \"salary\",\n","      \"producer_id\": {\n","        \"name\": \"BiLSTM Entity Mentions\",\n","        \"version\": \"1.0.0\"\n","      },\n","      \"confidence\": 0.9999942779541016,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    }\n","  ],\n","  \"producer_id\": {\n","    \"name\": \"BiLSTM Entity Mentions\",\n","    \"version\": \"1.0.0\"\n","  }\n","}"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["# Run the BILSTM model\n","syntax_result = syntax_model.run(text)\n","bilstm_result = bilstm_custom.run(syntax_result)\n","\n","bilstm_result"]},{"cell_type":"markdown","metadata":{},"source":["Now you are able to run the trained models on new data. You will run the models on the test data so that the results can also be used for model evaluation.\n","\n","Watson NLP includes methods for quality testing supported models. Given a model and test data, a quality report can be generated. The following example includes the steps required to generate a quality report for a BiLSTM entity mention extactor model. The same example can be applied to any entity mention extractor model."]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: Only Micro_avg metrics could be calculated based on the information available for this block type.\n"]},{"name":"stdout","output_type":"stream","text":["{\n","    \"per_class_confusion_matrix\": {\n","        \"field_of_study\": {\n","            \"true_positive\": 1000,\n","            \"false_positive\": 0,\n","            \"false_negative\": 0,\n","            \"precision\": 1.0,\n","            \"recall\": 1.0,\n","            \"f1\": 1.0\n","        },\n","        \"employee_id\": {\n","            \"true_positive\": 1000,\n","            \"false_positive\": 0,\n","            \"false_negative\": 0,\n","            \"precision\": 1.0,\n","            \"recall\": 1.0,\n","            \"f1\": 1.0\n","        },\n","        \"salary\": {\n","            \"true_positive\": 1000,\n","            \"false_positive\": 0,\n","            \"false_negative\": 0,\n","            \"precision\": 1.0,\n","            \"recall\": 1.0,\n","            \"f1\": 1.0\n","        },\n","        \"degree_level\": {\n","            \"true_positive\": 1000,\n","            \"false_positive\": 0,\n","            \"false_negative\": 0,\n","            \"precision\": 1.0,\n","            \"recall\": 1.0,\n","            \"f1\": 1.0\n","        }\n","    },\n","    \"macro_true_positive\": null,\n","    \"macro_false_positive\": null,\n","    \"macro_false_negative\": null,\n","    \"macro_precision\": 1.0,\n","    \"macro_recall\": 1.0,\n","    \"macro_f1\": 1.0,\n","    \"micro_precision\": 1.0,\n","    \"micro_recall\": 1.0,\n","    \"micro_f1\": 1.0,\n","    \"overall_tp\": 4000,\n","    \"overall_fp\": 0,\n","    \"overall_fn\": 0,\n","    \"detailed_metrics\": [],\n","    \"micro_precision_partial_match\": 0.0,\n","    \"micro_recall_partial_match\": 0.0,\n","    \"micro_f1_partial_match\": 0.0\n","}\n"]}],"source":["# Execute the model and generate the quality report\n","preprocess_func = lambda raw_doc: syntax_model.run(raw_doc)\n","quality_report = bilstm_custom.evaluate_quality('faker_PII_text_test.json', \n","                                               preprocess_func)\n","\n","# Print the quality report\n","print(json.dumps(quality_report, indent=4))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"summary\"></a>\n","## 4. Summary"]},{"cell_type":"markdown","metadata":{},"source":["<span style=\"color:blue\">This notebook shows you how to use the Watson NLP library and how quickly and easily you can train and run different PII extraction models using Watson NLP.</span>"]},{"cell_type":"markdown","metadata":{},"source":["Please note that this content is made available to foster Embedded AI technology adoption. The content may include systems & methods pending patent with USPTO and protected under US Patent Laws. For redistribution of this content, IBM will use release process. For any questions please log an issue in the [GitHub](https://github.com/ibm-build-labs/Watson-NLP). \n","\n","Developed by IBM Build Lab \n","\n","Copyright - 2022 IBM Corporation "]}],"metadata":{"kernelspec":{"display_name":"Python 3.10 + GPU","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":1}
