{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Extract the Personal Identifiable Information (PII) using Watson NLP"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Use Case</h2>\n","\n","This notebook demonstrates how to extract PII entities using Watson NLP Custom train or Fine-tune models. PII extraction is the process of identifying and extracting personal information from a document or dataset. This information can include names, addresses, phone numbers, email addresses, Social Security numbers, Credit Card number, and other types of information that can be used to identify an individual. \n","\n","<h2>What you'll learn in this notebook</h2>\n","\n","Watson NLP offers  fine-tune functionality for custom training. This notebooks shows:\n","\n","* <b>BILSTM</b>: the BiLSTM network would take the preprocessed text as input and learn to identify patterns and relationships between words that are indicative of PII data. The BiLSTM network would then output a probability score for each word in the text, indicating the likelihood that the word is part of a PII entity. The BiLSTM network may also be trained to recognize specific entities such as names, addresses, phone numbers, email addresses, etc.\n","\n","\n","* <b>SIRE</b>: Statistical Information and Relation Extraction (SIRE) is a technique used in natural language processing (NLP) to extract specific information and relationships from text. It involves using machine learning algorithms to identify and extract structured data such as entities, attributes, and relations from unstructured text. SIRE is used in a variety of applications, including information extraction, knowledge graph construction, and question answering. SIRE typically uses supervised learning approach, where a model is trained using annotated examples of text and the corresponding structured data. The model can then be used to extract the same information from new, unseen text."]},{"cell_type":"markdown","metadata":{},"source":["## Table of Contents\n","\n","\n","1. [Before you start](#beforeYouStart)\n","1. [Load Entity PII Models](#LoadModel)\n","1. [Preparing Training Data](#TrainingData)\n","   1. [Preparing Driving Licence Number Training Data](#DLNData)\n","   1. [Preparing More Custom PII Training Data](#CustumPII)\n","1. [Watson NLP Models](#NLPModels)    \n","   1.  [BiLSTM Fine-tuned](#BILSTMFINE)\n","   1.  [SIRE Fine-tuned](#SIRETune)\n","   1.  [SIRE Fine-Tune Model For Driving License Number](#DLNFine)\n","1. [Summary](#summary)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"beforeYouStart\"></a>\n","### 1. Before you start\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-danger\">\n","<b>Stop kernel of other notebooks.</b></div>\n","\n","**Note:** If you have other notebooks currently running with the _Default Python 3.x environment, **stop their kernels** before running this notebook. All these notebooks share the same runtime environment, and if they are running in parallel, you may encounter memory issues. To stop the kernel of another notebook, open that notebook, and select _File > Stop Kernel_.\n","\n","<div class=\"alert alert-block alert-warning\">\n","<b>Set Project token.</b></div>\n","\n","Before you can begin working on this notebook in Watson Studio in Cloud Pak for Data as a Service, you need to ensure that the project token is set so that you can access the project assets via the notebook.\n","\n","When this notebook is added to the project, a project access token should be inserted at the top of the notebook in a code cell. If you do not see the cell above, add the token to the notebook by clicking **More > Insert project token** from the notebook action bar.  By running the inserted hidden code cell, a project object is created that you can use to access project resources.\n","\n","![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n","\n","<div class=\"alert alert-block alert-info\">\n","<b>Tip:</b> Cell execution</div>\n","\n","Note that you can step through the notebook execution cell by cell, by selecting Shift-Enter. Or you can execute the entire notebook by selecting **Cell -> Run All** from the menu."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting faker\n","  Downloading Faker-17.0.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /opt/conda/envs/Python-3.10-CUDA/lib/python3.10/site-packages (from faker) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.10-CUDA/lib/python3.10/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n","Installing collected packages: faker\n","Successfully installed faker-17.0.0\n"]}],"source":["!pip install faker"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import json\n","import pandas as pd\n","import watson_nlp\n","import random\n","import string\n","from faker import Faker\n","from watson_nlp import data_model as dm\n","from watson_nlp.toolkit.entity_mentions_utils import prepare_train_from_json"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Silence Tensorflow warnings\n","import tensorflow as tf\n","tf.get_logger().setLevel('ERROR')\n","tf.autograph.set_verbosity(0)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"LoadModel\"></a>\n","### 2. Load Entity PII Models"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Load a syntax model to split the text into sentences and tokens\n","syntax_model = watson_nlp.load(watson_nlp.download('syntax_izumo_en_stock'))\n","# Load bilstm model in WatsonNLP\n","bilstm_model = watson_nlp.load(watson_nlp.download('entity-mentions_bilstm_en_pii'))\n","# Download the GloVe model to be used as embeddings in the BiLSTM\n","glove_model = watson_nlp.load(watson_nlp.download('embedding_glove_en_stock'))\n","# Download the algorithm template\n","mentions_train_template = watson_nlp.load(watson_nlp.download('file_path_entity-mentions_sire_multi_template-crf'))\n","# Download the feature extractor\n","default_feature_extractor = watson_nlp.load(watson_nlp.download('feature-extractor_rbr_entity-mentions_sire_en_stock'))\n","# Load rbr model in WatsonNLP\n","rbr_model = watson_nlp.load(watson_nlp.download('entity-mentions_rbr_multi_pii'))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"TrainingData\"></a>\n","### 3. Preparing Training Data"]},{"cell_type":"markdown","metadata":{},"source":["Let's generate sentences using Faker Library. Ideally, the sentences would include Driving Licence Number, Name, SSN, and Credit Card Number, Educational Details, Employee ID, Salary in context."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"DLNData\"></a>\n","### 3.1 Preparing Driving Licence Number Training Data"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["fake = Faker(locale='en_US') "]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["#Driving Licence Number\n","\n","#Colorado\n","def generate_driving_license_Colarado():\n","    license_number = fake.numerify('##-###-####')\n","    name = fake.name()\n","    state = \"Colarado\"\n","    return license_number, name, state\n","\n","#Alaska & Alabama\n","def generate_driving_license_Alaska():\n","    license_number = fake.numerify('#######')\n","    name = fake.name()\n","    state = random.choice([\"Alaska\",\"Alabama\"])\n","    return license_number, name, state\n","\n","#Arkansas & South Carolina\n","def generate_driving_license_SCarolina():\n","    license_number = f\"{9}{fake.numerify('########')}\"\n","    name = fake.name()\n","    state = random.choice([\"Arkansas\",\"South Carolina\"])\n","    return license_number, name, state\n","\n","#California\n","def generate_driving_license_California():\n","    license_number = f\"{'A'}{fake.numerify('########')}\"\n","    name = fake.name()\n","    state = random.choice([\"California\"])\n","    return license_number, name, state\n","\n","#Hawaii\n","def generate_driving_license_Hawaii():\n","    license_number = f\"{'H'}{fake.numerify('########')}\"\n","    name = fake.name()\n","    state = random.choice([\"Hawaii\"])\n","    return license_number, name, state\n","\n","#New York\n","def generate_driving_license_New_York():\n","    license_number = fake.numerify('### ### ###')\n","    name = fake.name()\n","    state = random.choice([\"New York\"])\n","    return license_number, name, state\n","\n","#North Carolina\n","def generate_driving_license_NCarolina():\n","    license_number = fake.numerify('############')\n","    name = fake.name()\n","    state = random.choice([\"North Carolina\"])\n","    return license_number, name, state\n","\n","#California\n","def generate_driving_license_California():\n","    license_number = f\"{'A'}{fake.numerify('########')}\"\n","    name = fake.name()\n","    state = random.choice([\"California\"])\n","    return license_number, name, state\n","\n","#Texas\n","def generate_driving_license_Texas():\n","    license_number = f\"{'A'}{fake.numerify('########')}\"\n","    name = fake.name()\n","    state = random.choice([\"California\"])\n","    return license_number, name, state\n","\n","def format_DLN_data():\n","    State_DLN = random.choice([generate_driving_license_Colarado(), generate_driving_license_Alaska(), generate_driving_license_SCarolina(), generate_driving_license_California(), generate_driving_license_Hawaii(), generate_driving_license_New_York(), generate_driving_license_NCarolina(), generate_driving_license_Texas()])\n","    driving_license, name, state = State_DLN\n","\n","    text_1 = \"My name is %s I belong to the %s , My Driving License number is %s.\" %(name, state, driving_license)\n","    text_2 = \"I am %s. %s this is my driving license number. I am from %s state.\" %(name, driving_license, state)\n","    text_3 = \"Hello, My self %s, I am living in %s and my driving License number is %s\"  %(name, state, driving_license)\n","    text = random.choice([text_1, text_2, text_3])\n","    \n","    \n","    name_begin = text.find(name)\n","    name_end = name_begin + len(name)\n","    state_begin = text.find(state)\n","    state_end = state_begin + len(state)\n","    driving_license_begin = text.find(driving_license)\n","    driving_license_end = driving_license_begin + len(driving_license)\n","    \n","    \n","    data = {\n","                \"text\": text,\n","                \"mentions\": [\n","                    {\n","                        \"location\": {\n","                            \"begin\": name_begin,\n","                            \"end\": name_end\n","                        },\n","                        \"text\": name,\n","                        \"type\": \"Name\"\n","                    },\n","                    {\n","                        \"location\": {\n","                            \"begin\": state_begin,\n","                            \"end\": state_end\n","                        },\n","                        \"text\": state,\n","                        \"type\": \"state\"\n","                    },\n","                    {\n","                        \"location\": {\n","                            \"begin\": driving_license_begin,\n","                            \"end\": driving_license_end\n","                        },\n","                        \"text\": driving_license,\n","                        \"type\": \"driving_license_number\"\n","                    },\n","                ]   \n","            }\n","    \n","    return data"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def format_DLN_data():\n","    State_DLN = random.choice([generate_driving_license_Colarado(), generate_driving_license_Alaska(), generate_driving_license_SCarolina(), generate_driving_license_California(), generate_driving_license_Hawaii(), generate_driving_license_New_York(), generate_driving_license_NCarolina(), generate_driving_license_Texas()])\n","    driving_license, name, state = State_DLN\n","\n","    text_1 = \"My name is %s I belong to the %s , My Driving License number is %s.\" %(name, state, driving_license)\n","    text_2 = \"I am %s. %s this is my driving license number. I am from %s state.\" %(name, driving_license, state)\n","    text_3 = \"Hello, My self %s, I am living in %s and my driving License number is %s\"  %(name, state, driving_license)\n","    text = random.choice([text_1, text_2, text_3])\n","    \n","    \n","    name_begin = text.find(name)\n","    name_end = name_begin + len(name)\n","    state_begin = text.find(state)\n","    state_end = state_begin + len(state)\n","    driving_license_begin = text.find(driving_license)\n","    driving_license_end = driving_license_begin + len(driving_license)\n","    \n","    \n","    data = {\n","                \"text\": text,\n","                \"mentions\": [\n","                    {\n","                        \"location\": {\n","                            \"begin\": name_begin,\n","                            \"end\": name_end\n","                        },\n","                        \"text\": name,\n","                        \"type\": \"Name\"\n","                    },\n","                    {\n","                        \"location\": {\n","                            \"begin\": state_begin,\n","                            \"end\": state_end\n","                        },\n","                        \"text\": state,\n","                        \"type\": \"state\"\n","                    },\n","                    {\n","                        \"location\": {\n","                            \"begin\": driving_license_begin,\n","                            \"end\": driving_license_end\n","                        },\n","                        \"text\": driving_license,\n","                        \"type\": \"driving_license_number\"\n","                    },\n","                ]   \n","            }\n","    \n","    return data"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["{'text': 'I am Michael Mendoza. 915 288 496 this is my driving license number. I am from New York state.',\n"," 'mentions': [{'location': {'begin': 5, 'end': 20},\n","   'text': 'Michael Mendoza',\n","   'type': 'Name'},\n","  {'location': {'begin': 79, 'end': 87}, 'text': 'New York', 'type': 'state'},\n","  {'location': {'begin': 22, 'end': 33},\n","   'text': '915 288 496',\n","   'type': 'driving_license_number'}]}"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["format_DLN_data()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["{'file_name': 'PII_faker_LicenseNumber_text_train.json',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': 'a83ae8a8-3fcf-4761-a966-e731727c0e55'}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["#Prepared and store Training dataset for Driving License dataset\n","train_list_faker = []\n","for i in range(0, 10000):\n","    train_list_faker.append(format_DLN_data())\n","\n","with open('PII_faker_LicenseNumber_text_train.json', 'w') as f:\n","    json.dump(train_list_faker, f)\n","project.save_data('PII_faker_LicenseNumber_text_train.json', data=json.dumps(train_list_faker), overwrite=True)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"CustumPII\"></a>\n","### 3.2 Preparing More Custom PII Training Data \n","\n","* Name\n","* Social Security Number \n","* Credit Card Number \n","* Employee ID\n","* Education Details \n","* Salary\n"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["def format_data():  \n","        #Generate a random\n","        name = fake.name() \n","\n","        #Generate a random SSN \n","        ssn = fake.ssn()\n","\n","        #Generate a random CCN \n","        ccn = fake.credit_card_number()\n","\n","        # Generate a random degree level\n","        degree_level = fake.random_element(elements=('Bachelor\\'s', 'Master\\'s', 'Doctorate'))\n","\n","        # Generate a random field of study\n","        field_of_study = fake.random_element(elements=('Computer Science', 'Engineering', 'Business', 'Psychology','Medical'))\n","\n","        # Generate a random prefix with 1-2 alphabets\n","        prefix = ''.join(random.choices(string.ascii_uppercase, k=random.randint(1, 2)))\n","        # Generate a random employee ID with the prefix and a random integer\n","        employee_id = f\"{prefix}{fake.random_int(min=10000, max=99999):05d}\"\n","\n","        # Generate salary using faker\n","        salary = str(fake.pyfloat(left_digits=5, right_digits=2, positive=True, min_value=1000, max_value=5000))\n","\n","\n","        text_1 = \"\"\"My name is %s, and my social security number is %s. Here's the number to my Visa credit card, \n","        %s. I studied %s in %s, My employee id is %s and salary is %s\"\"\" % (name, ssn, ccn,degree_level,field_of_study,employee_id,salary)\n","\n","        text_2 = \"\"\"%s is my social security number. The name on my credit card %s is %s. \n","        My employee id is %s and I done my %s in %s, I am earning %s per month\"\"\" % (ssn, ccn, name,employee_id,degree_level, field_of_study,salary)\n","\n","        text_3 = \"\"\"My monthly Earning is %s and employee code is %s, I studied %s in %s. \n","        My credit card number is %s and social security number is %s, I am %s\"\"\" %(salary,employee_id,degree_level,field_of_study,ccn,ssn,name)\n","\n","\n","        text = random.choice([text_1, text_2,text_3])\n","\n","        name_begin = text.find(name)\n","        name_end = text.find(name) + len(name)\n","\n","        ssn_begin = text.find(ssn)\n","        ssn_end = text.find(ssn) + len(ssn)\n","\n","        ccn_begin = text.find(ccn)\n","        ccn_end = text.find(ccn) + len(ccn)\n","\n","        field_of_study_begin = text.find(field_of_study)\n","        field_of_study_end = field_of_study_begin + len(field_of_study)\n","\n","        degree_level_begin = text.find(degree_level)\n","        degree_level_end = degree_level_begin + len(degree_level)\n","\n","        employee_id_begin = text.find(employee_id)\n","        employee_id_end = employee_id_begin + len(employee_id)\n","\n","        salary_begin = text.find(salary)\n","        salary_end = salary_begin + len(salary)\n","\n","        data = {\n","                    \"text\": text,\n","                    \"mentions\": [\n","                        {\n","                            \"location\": {\n","                                \"begin\": field_of_study_begin,\n","                                \"end\": field_of_study_end\n","                            },\n","                            \"text\": field_of_study,\n","                            \"type\": \"field_of_study\"\n","                        },\n","                        {\n","                            \"location\": {\n","                                \"begin\": degree_level_begin,\n","                                \"end\": degree_level_end\n","                            },\n","                            \"text\": degree_level,\n","                            \"type\": \"degree_level\"\n","                        },\n","                        {\n","                            \"location\": {\n","                                \"begin\": employee_id_begin,\n","                                \"end\": employee_id_end\n","                            },\n","                            \"text\": employee_id,\n","                            \"type\": \"employee_id\"\n","                        },\n","                        {\n","                            \"location\": {\n","                                \"begin\": salary_begin,\n","                                \"end\": salary_end\n","                            },\n","                            \"text\": salary,\n","                            \"type\": \"salary\"\n","                        },\n","                        {\n","                            \"location\": {\n","                                \"begin\": name_begin,\n","                                \"end\": name_end\n","                            },\n","                            \"text\": name,\n","                            \"type\": \"Name\"\n","                        },\n","                        {\n","                            \"location\": {\n","                                \"begin\": ssn_begin,\n","                                \"end\": ssn_end\n","                            },\n","                            \"text\": ssn,\n","                            \"type\": \"SocialSecurityNumber\"\n","                        },\n","                        {\n","                            \"location\": {\n","                                \"begin\": ccn_begin,\n","                                \"end\": ccn_end\n","                            },\n","                            \"text\": ccn,\n","                            \"type\": \"CreditCardNumber\"\n","                        }\n","                        ]   \n","                    }\n","        return data"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"data":{"text/plain":["{'text': \"My name is Christopher Barron, and my social security number is 358-23-4573. Here's the number to my Visa credit card, \\n        4613026413118. I studied Bachelor's in Computer Science, My employee id is E14465 and salary is 3548.1\",\n"," 'mentions': [{'location': {'begin': 167, 'end': 183},\n","   'text': 'Computer Science',\n","   'type': 'field_of_study'},\n","  {'location': {'begin': 153, 'end': 163},\n","   'text': \"Bachelor's\",\n","   'type': 'degree_level'},\n","  {'location': {'begin': 203, 'end': 209},\n","   'text': 'E14465',\n","   'type': 'employee_id'},\n","  {'location': {'begin': 224, 'end': 230}, 'text': '3548.1', 'type': 'salary'},\n","  {'location': {'begin': 11, 'end': 29},\n","   'text': 'Christopher Barron',\n","   'type': 'Name'},\n","  {'location': {'begin': 64, 'end': 75},\n","   'text': '358-23-4573',\n","   'type': 'SocialSecurityNumber'},\n","  {'location': {'begin': 128, 'end': 141},\n","   'text': '4613026413118',\n","   'type': 'CreditCardNumber'}]}"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["format_data()"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"data":{"text/plain":["{'file_name': 'faker_PII_text_train.json',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': 'e952dfbd-f642-4712-b7a5-deae8425af2a'}"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["#Prepared and store Training dataset for Driving License dataset\n","train_list_faker = []\n","for i in range(0, 10000):\n","    train_list_faker.append(format_data())\n","\n","with open('faker_PII_text_train.json', 'w') as f:\n","    json.dump(train_list_faker, f)\n","project.save_data('faker_PII_text_train.json', data=json.dumps(train_list_faker), overwrite=True)"]},{"cell_type":"markdown","metadata":{},"source":["Save the sentences into a json training file and a json dev file. This will save the file to the runtime local as well as the project data assets."]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"data":{"text/plain":["{'file_name': 'faker_PII_text_test.json',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': '0059c8e9-2566-4288-a1c2-092dc29d418e'}"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["#Prepared and store Training dataset for Driving License dataset\n","test_list_faker = []\n","for i in range(0, 1000):\n","    test_list_faker.append(format_data())\n","\n","with open('faker_PII_text_test.json', 'w') as f:\n","    json.dump(test_list_faker, f)\n","project.save_data('faker_PII_text_test.json', data=json.dumps(test_list_faker), overwrite=True)"]},{"cell_type":"markdown","metadata":{},"source":["Since the data is already formatted correctly, the following process is needed to read the JSON data files from Watson Studio project assets and save them to the runtime working directory where they will be used as input for training the models."]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[],"source":["train_data = dm.DataStream.from_json_array(\"faker_PII_text_train.json\")\n","train_iob_stream = prepare_train_from_json(train_data, syntax_model)\n","dev_data = dm.DataStream.from_json_array(\"faker_PII_text_test.json\")\n","dev_iob_stream = prepare_train_from_json(dev_data, syntax_model)"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"data":{"text/plain":["'826-32-8586 is my social security number. The name on my credit card 6011757841400152 is Luke Lindsey. \\n        My employee id is YL11348 and I done my Doctorate in Medical, I am earning 1578.21 per month'"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["text = pd.read_json('faker_PII_text_test.json')['text'][1]\n","text"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"NLPModels\"></a>\n","### 4. Watson NLP Models"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"BILSTMFINE\"></a>\n","\n","### 4.1 BiLSTM Fine-tuned"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["940/940 [==============================] - 23s 25ms/step - loss: 0.4144 - val_loss: 0.0268\n","940/940 [==============================] - 16s 17ms/step - loss: 0.0256 - val_loss: 0.0062\n","940/940 [==============================] - 17s 18ms/step - loss: 0.0102 - val_loss: 0.0024\n","940/940 [==============================] - 16s 17ms/step - loss: 0.0054 - val_loss: 0.0011\n","940/940 [==============================] - 16s 17ms/step - loss: 0.0032 - val_loss: 5.5202e-04\n"]}],"source":["#Fine-Tune BiLSTM model using Custom PII\n","bilstm_custom = bilstm_model.train(train_iob_stream, \n","                                   dev_iob_stream, \n","                                   embedding=glove_model.embedding,\n","                                   num_train_epochs=5,\n","                                   num_conf_epochs=5, \n","                                   checkpoint_interval=5, \n","                                   learning_rate=0.005,\n","                                   lstm_size=16, \n","                                  )"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[{"data":{"text/plain":["{'file_name': 'bilstm_pii_custom',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': '7cb485ec-42c3-4a4d-aa10-37502be1266f'}"]},"execution_count":97,"metadata":{},"output_type":"execute_result"}],"source":["project.save_data('bilstm_pii_custom', data=bilstm_custom.as_file_like_object(), overwrite=True)"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Text:  826-32-8586     Type:  SocialSecurityNumber\n","Text:  6011757841400152 Type:  CreditCardNumber\n","Text:  Luke Lindsey    Type:  Name\n","Text:  YL11348         Type:  employee_id\n","Text:  Doctorate       Type:  degree_level\n","Text:  Medical         Type:  field_of_study\n","Text:  1578.21         Type:  salary\n"]}],"source":["syntax_result = syntax_model.run(text)\n","bilstm_result = bilstm_custom.run(syntax_result)\n","\n","for i in bilstm_result.mentions:\n","    print(\"Text: \", i.span.text.ljust(15, \" \"), \"Type: \", i.type)"]},{"cell_type":"markdown","metadata":{},"source":["Now you are able to run the trained models on new data. You will run the models on the test data so that the results can also be used for model evaluation.\n","\n","Watson NLP includes methods for quality testing supported models. Given a model and test data, a quality report can be generated. The following example includes the steps required to generate a quality report for a BiLSTM entity mention extactor model. The same example can be applied to any entity mention extractor model."]},{"cell_type":"code","execution_count":116,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: Only Micro_avg metrics could be calculated based on the information available for this block type.\n"]},{"name":"stdout","output_type":"stream","text":["{\n","    \"per_class_confusion_matrix\": {\n","        \"salary\": {\n","            \"true_positive\": 1000,\n","            \"false_positive\": 0,\n","            \"false_negative\": 0,\n","            \"precision\": 1.0,\n","            \"recall\": 1.0,\n","            \"f1\": 1.0\n","        },\n","        \"CreditCardNumber\": {\n","            \"true_positive\": 1000,\n","            \"false_positive\": 0,\n","            \"false_negative\": 0,\n","            \"precision\": 1.0,\n","            \"recall\": 1.0,\n","            \"f1\": 1.0\n","        },\n","        \"employee_id\": {\n","            \"true_positive\": 1000,\n","            \"false_positive\": 0,\n","            \"false_negative\": 0,\n","            \"precision\": 1.0,\n","            \"recall\": 1.0,\n","            \"f1\": 1.0\n","        },\n","        \"field_of_study\": {\n","            \"true_positive\": 1000,\n","            \"false_positive\": 0,\n","            \"false_negative\": 0,\n","            \"precision\": 1.0,\n","            \"recall\": 1.0,\n","            \"f1\": 1.0\n","        },\n","        \"Name\": {\n","            \"true_positive\": 1000,\n","            \"false_positive\": 0,\n","            \"false_negative\": 0,\n","            \"precision\": 1.0,\n","            \"recall\": 1.0,\n","            \"f1\": 1.0\n","        },\n","        \"SocialSecurityNumber\": {\n","            \"true_positive\": 1000,\n","            \"false_positive\": 0,\n","            \"false_negative\": 0,\n","            \"precision\": 1.0,\n","            \"recall\": 1.0,\n","            \"f1\": 1.0\n","        },\n","        \"degree_level\": {\n","            \"true_positive\": 1000,\n","            \"false_positive\": 0,\n","            \"false_negative\": 0,\n","            \"precision\": 1.0,\n","            \"recall\": 1.0,\n","            \"f1\": 1.0\n","        }\n","    },\n","    \"macro_true_positive\": null,\n","    \"macro_false_positive\": null,\n","    \"macro_false_negative\": null,\n","    \"macro_precision\": 1.0,\n","    \"macro_recall\": 1.0,\n","    \"macro_f1\": 1.0,\n","    \"micro_precision\": 1.0,\n","    \"micro_recall\": 1.0,\n","    \"micro_f1\": 1.0,\n","    \"overall_tp\": 7000,\n","    \"overall_fp\": 0,\n","    \"overall_fn\": 0,\n","    \"detailed_metrics\": [],\n","    \"micro_precision_partial_match\": 0.0,\n","    \"micro_recall_partial_match\": 0.0,\n","    \"micro_f1_partial_match\": 0.0\n","}\n"]}],"source":["# Execute the model and generate the quality report\n","preprocess_func = lambda raw_doc: syntax_model.run(raw_doc)\n","quality_report = bilstm_custom.evaluate_quality('faker_PII_text_test.json', \n","                                               preprocess_func)\n","\n","# Print the quality report\n","print(json.dumps(quality_report, indent=4))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"SIRETune\"></a>\n","\n","### 4.2 SIRE Fine-tuned\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["#help(watson_nlp.blocks.entity_mentions.SIRE)"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Initializing viterbi classifier\n","\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n","\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n","Get Feature str 1047923\n","Done get feature str 1047923\n","done. [88\u001b[33mg\u001b[0m508\u001b[33mm\u001b[0m380\u001b[33mk\u001b[0m,17\u001b[33mg\u001b[0m181\u001b[33mm\u001b[0m192\u001b[33mk\u001b[0m]\n","gramSize = 2\n","number of processes: 5\n","Initial processing:  (# of words: 432744, # of sentences: 30077)\n","senIndex[1] = 6031, wordIndex = 86551\n","senIndex[2] = 12062, wordIndex = 173097\n","senIndex[3] = 18077, wordIndex = 259647\n","senIndex[4] = 24102, wordIndex = 346200\n","senIndex[5] = 30076, wordIndex = 432744\n","\u001b[32m[ME_CRF::scaleModel]\u001b[0m Updater -- l1=\u001b[32m0.1\u001b[0m, l2=\u001b[32m0.005\u001b[0m, history size=\u001b[32m5\u001b[0m, progress windows size \u001b[32m20\u001b[0m\n"," Iteration           Obj             WErr                         Timing       %Eff        Per thread timing\n","              1100493.95      9.08/ 65.08             E:2.29 s, M:0.18 s.       1.00 [m:2.25, M:2.26, av:2.26]\n","         0   716838.93     32.15/ 88.77             E:2.32 s, M:0.18 s.       1.00 [m:2.27, M:2.29, av:2.29]\n","               786005.86     32.15/ 88.77             E:2.29 s, M:0.09 s.       1.00 [m:2.25, M:2.27, av:2.27]\n","         1   459917.70     32.15/ 88.77             E:2.28 s, M:0.20 s.       1.00 [m:2.24, M:2.26, av:2.26]\n","         2   212835.83     13.75/ 88.77             E:2.29 s, M:0.22 s.       1.00 [m:2.25, M:2.26, av:2.26]\n","         3   140524.64     13.27/ 88.77             E:2.38 s, M:0.29 s.       1.00 [m:2.32, M:2.35, av:2.35]\n","         4    49795.08      0.13/  1.11             E:2.34 s, M:0.26 s.       1.00 [m:2.29, M:2.31, av:2.31]\n","         5    22702.98      0.06/  0.78             E:2.26 s, M:0.25 s.       1.00 [m:2.22, M:2.24, av:2.24]\n","         6    12949.91      0.03/  0.49             E:2.28 s, M:0.25 s.       1.00 [m:2.23, M:2.26, av:2.25]\n","         7     8651.41      0.02/  0.29             E:2.30 s, M:0.25 s.       1.00 [m:2.24, M:2.28, av:2.27]\n","         8     6673.94      0.02/  0.22             E:2.31 s, M:0.26 s.       1.00 [m:2.26, M:2.28, av:2.28]\n","         9     4883.21      0.01/  0.16             E:2.27 s, M:0.26 s.       1.00 [m:2.23, M:2.25, av:2.25]\n","        10     3336.58      0.01/  0.09             E:2.30 s, M:0.26 s.       1.00 [m:2.26, M:2.28, av:2.28]\n","        11     2416.68      0.00/  0.04             E:2.39 s, M:0.33 s.       1.00 [m:2.33, M:2.35, av:2.35]\n","        12     1805.58      0.00/  0.01             E:2.39 s, M:0.26 s.       1.00 [m:2.35, M:2.35, av:2.35]\n","        13     1202.54      0.00/  0.00             E:2.27 s, M:0.26 s.       1.00 [m:2.22, M:2.24, av:2.24]\n","        14      970.02      0.00/  0.00             E:2.31 s, M:0.26 s.       1.00 [m:2.26, M:2.29, av:2.28]\n","        15      786.84      0.00/  0.00             E:2.32 s, M:0.26 s.       1.00 [m:2.26, M:2.30, av:2.29]\n","        16      493.85      0.00/  0.00             E:2.28 s, M:0.25 s.       1.00 [m:2.25, M:2.26, av:2.26]\n","        17      318.40      0.00/  0.00             E:2.28 s, M:0.24 s.       1.00 [m:2.24, M:2.26, av:2.26]\n","        18      256.12      0.00/  0.00             E:2.31 s, M:0.25 s.       1.00 [m:2.26, M:2.28, av:2.28]\n","        19      201.85      0.00/  0.00             E:2.31 s, M:0.25 s.       1.00 [m:2.27, M:2.30, av:2.29]\n","Not enough progress in the last 5 iters.. converged.\n","    Thread     Total      Wait Effective      %Eff         #Sents/sec\n","         0     50.03      0.05     49.98      1.00             2653.44\n","         1     50.19      0.11     50.08      1.00             2627.18\n","         2     50.20      0.11     50.08      1.00             2636.13\n","         3     50.16      0.09     50.07      1.00             2633.40\n","         4     50.13      0.09     50.05      1.00             2645.95\n","Parent: the end!\n","Initializing viterbi classifier\n","\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n","\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n"]}],"source":["#Fine-Tune SIRE using custom PII\n","sire_custom = watson_nlp.blocks.entity_mentions.SIRE.train(train_iob_stream, \n","                                                           'en', \n","                                                           mentions_train_template,\n","                                                           feature_extractors=[default_feature_extractor])"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Saved 36428 features.\n"]},{"data":{"text/plain":["{'file_name': 'sire_pii_custom',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': '3b572121-d3e2-439d-8622-813f6536f335'}"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["project.save_data('sire_pii_custom', data=sire_custom.as_file_like_object(), overwrite=True)"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Text:  826-32-8586     Type:  SocialSecurityNumber\n","Text:  6011757841400152 Type:  CreditCardNumber\n","Text:  Luke Lindsey    Type:  Name\n","Text:  YL11348         Type:  employee_id\n","Text:  Doctorate       Type:  degree_level\n","Text:  Medical         Type:  field_of_study\n","Text:  1578.21         Type:  salary\n"]}],"source":["syntax_result = syntax_model.run(text)\n","sire_result = sire_custom.run(syntax_result)\n","\n","for i in sire_result.mentions:\n","    print(\"Text: \", i.span.text.ljust(15, \" \"), \"Type: \", i.type)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"DLNFine\"></a>\n","### 4.3 SIRE Fine-Tune Model For Driving License Number "]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["#load the DLN dataset\n","train_data = dm.DataStream.from_json_array(\"PII_faker_LicenseNumber_text_train.json\")\n","train_iob_stream = prepare_train_from_json(train_data, syntax_model)\n","\n","dev_data = dm.DataStream.from_json_array(\"PII_faker_LicenseNumber_text_train.json\")\n","dev_iob_stream = prepare_train_from_json(dev_data, syntax_model)"]},{"cell_type":"markdown","metadata":{},"source":["Download the Custom RBR rules for Driving License Number (Generated by Elyra Visual NLP Editor)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Initializing viterbi classifier\n","\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n","\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n","Get Feature str 405250\n","Done get feature str 405250\n","done. [76\u001b[33mg\u001b[0m73\u001b[33mm\u001b[0m756\u001b[33mk\u001b[0m,10\u001b[33mg\u001b[0m44\u001b[33mm\u001b[0m36\u001b[33mk\u001b[0m]\n","gramSize = 2\n","number of processes: 5\n","Initial processing:  (# of words: 201601, # of sentences: 16570)\n","senIndex[1] = 3382, wordIndex = 40328\n","senIndex[2] = 6652, wordIndex = 80652\n","senIndex[3] = 9984, wordIndex = 120972\n","senIndex[4] = 13260, wordIndex = 161285\n","senIndex[5] = 16569, wordIndex = 201601\n","\u001b[32m[ME_CRF::scaleModel]\u001b[0m Updater -- l1=\u001b[32m0.1\u001b[0m, l2=\u001b[32m0.005\u001b[0m, history size=\u001b[32m5\u001b[0m, progress windows size \u001b[32m20\u001b[0m\n"," Iteration           Obj             WErr                         Timing       %Eff        Per thread timing\n","               388303.43     19.65/ 81.21             E:0.67 s, M:0.05 s.       1.00 [m:0.65, M:0.66, av:0.66]\n","         0   210151.93     27.29/100.00             E:0.65 s, M:0.05 s.       1.00 [m:0.64, M:0.65, av:0.65]\n","         1   128292.64     27.29/100.00             E:0.64 s, M:0.05 s.       1.00 [m:0.62, M:0.63, av:0.63]\n","         2    74750.15     17.11/ 79.34             E:0.63 s, M:0.06 s.       1.00 [m:0.61, M:0.62, av:0.62]\n","         3    34631.79      2.34/ 17.21             E:0.63 s, M:0.06 s.       1.00 [m:0.62, M:0.63, av:0.63]\n","         4    11103.52      0.14/  1.73             E:0.64 s, M:0.07 s.       1.00 [m:0.63, M:0.64, av:0.64]\n","         5     5025.77      0.10/  1.09             E:0.64 s, M:0.06 s.       1.00 [m:0.62, M:0.63, av:0.63]\n","         6     3509.28      0.05/  0.59             E:0.64 s, M:0.06 s.       1.00 [m:0.63, M:0.64, av:0.63]\n","         7     2332.96      0.03/  0.36             E:0.63 s, M:0.06 s.       1.00 [m:0.62, M:0.63, av:0.63]\n","         8     1664.78      0.02/  0.22             E:0.64 s, M:0.07 s.       1.00 [m:0.63, M:0.64, av:0.63]\n","         9     1262.99      0.00/  0.01             E:0.63 s, M:0.07 s.       1.00 [m:0.62, M:0.63, av:0.62]\n","        10      996.13      0.00/  0.00             E:0.64 s, M:0.07 s.       1.00 [m:0.62, M:0.63, av:0.63]\n","        11      689.25      0.00/  0.00             E:0.64 s, M:0.06 s.       1.00 [m:0.62, M:0.63, av:0.63]\n","        12      503.14      0.00/  0.00             E:0.63 s, M:0.07 s.       1.00 [m:0.61, M:0.62, av:0.62]\n","        13      378.56      0.00/  0.00             E:0.63 s, M:0.07 s.       1.00 [m:0.62, M:0.63, av:0.63]\n","        14      291.25      0.00/  0.00             E:0.63 s, M:0.06 s.       1.00 [m:0.62, M:0.63, av:0.63]\n","        15      205.49      0.00/  0.00             E:0.63 s, M:0.06 s.       1.00 [m:0.62, M:0.63, av:0.63]\n","        16      168.90      0.00/  0.00             E:0.63 s, M:0.06 s.       1.00 [m:0.62, M:0.63, av:0.62]\n","        17      147.50      0.00/  0.00             E:0.62 s, M:0.06 s.       1.00 [m:0.61, M:0.62, av:0.62]\n","        18      106.58      0.00/  0.00             E:0.62 s, M:0.06 s.       1.00 [m:0.60, M:0.61, av:0.61]\n","        19       95.09      0.00/  0.00             E:0.63 s, M:0.06 s.       1.00 [m:0.61, M:0.63, av:0.63]\n","Not enough progress in the last 5 iters.. converged.\n","    Thread     Total      Wait Effective      %Eff         #Sents/sec\n","         0     13.18      0.02     13.17      1.00             5288.27\n","         1     13.17      0.02     13.15      1.00             5305.35\n","         2     13.15      0.01     13.14      1.00             5283.49\n","         3     13.17      0.01     13.15      1.00             5284.76\n","         4     13.17      0.02     13.15      1.00             5262.41\n","Parent: the end!\n","Initializing viterbi classifier\n","\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n","\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n"]}],"source":["#Fine-Tune SIRE using Driving License number PII\n","sire_DLN_custom = watson_nlp.blocks.entity_mentions.SIRE.train(train_iob_stream, \n","                                                           'en', \n","                                                           mentions_train_template,\n","                                                           feature_extractors=[default_feature_extractor])"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["text1=\"Hello, My self Tracy Arias, I am living in Alaska and my driving License number is 9839434\"\n","text2=\"Hello, My self Shane Escobar, I am living in New York and my driving License number is 052 289 084\"\n","text3=\"Hello, My self Laura Parrish, I am living in Colarado and my driving License number is 25-157-3852\"\n","text4=\"My name is Curtis Mccullough I belong to the Alabama , My Driving License number is 1470583?\"\n","text5=\"I am Randall Barton. H45768237 this is my driving license number. I am from Hawaii state.\"\n","text6=\"Hello, My self Michael Peterson, I am living in Colarado and my driving License number is 87-361-4145\"\n","text7=\"Hello, My self Ms. Jennifer Hart, I am living in North Carolina and my driving License number is 844144533108\"\n","text8=\"Hello, My self Derek Martin, I am living in California and my driving License number is A06798902\"\n","text9=\"I am Lauren Martinez. 493 671 140 this is my driving license number. I am from New York state.\"\n","\n","all_test=[text1,text2,text3,text4,text5,text6,text7,text8,text9]"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Text1 Tracy Arias     Type:  Name\n","Text1 Alaska          Type:  state\n","Text1 9839434         Type:  driving_license_number\n","\n","\n","Text2 Shane Escobar   Type:  Name\n","Text2 New York        Type:  state\n","Text2 052 289 084     Type:  driving_license_number\n","\n","\n","Text3 Laura Parrish   Type:  Name\n","Text3 Colarado        Type:  state\n","Text3 25-157-3852     Type:  driving_license_number\n","\n","\n","Text4 Curtis Mccullough Type:  Name\n","Text4 Alabama         Type:  state\n","Text4 1470583?        Type:  driving_license_number\n","\n","\n","Text5 Randall Barton  Type:  Name\n","Text5 H45768237       Type:  driving_license_number\n","Text5 Hawaii          Type:  state\n","\n","\n","Text6 Michael Peterson Type:  Name\n","Text6 Colarado        Type:  state\n","Text6 87-361-4145     Type:  driving_license_number\n","\n","\n","Text7 Ms. Jennifer Hart Type:  Name\n","Text7 North Carolina  Type:  state\n","Text7 844144533108    Type:  driving_license_number\n","\n","\n","Text8 Derek Martin    Type:  Name\n","Text8 California      Type:  state\n","Text8 A06798902       Type:  driving_license_number\n","\n","\n","Text9 Lauren Martinez Type:  Name\n","Text9 493 671 140     Type:  driving_license_number\n","Text9 New York        Type:  state\n","\n","\n"]}],"source":["t=1\n","for test in all_test:\n","    syntax_result = syntax_model.run(test)\n","    sire_DLN_result = sire_DLN_custom.run(syntax_result)\n","\n","    for i in sire_DLN_result.mentions:\n","        print(\"Text\"+str(t), i.span.text.ljust(15, \" \"), \"Type: \", i.type)\n","    print(\"\\n\")\n","    t+=1  "]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"summary\"></a>\n","## 5. Summary"]},{"cell_type":"markdown","metadata":{},"source":["<span style=\"color:blue\">This notebook shows you how to use the Watson NLP library and how quickly and easily you can train and run different PII extraction models using Watson NLP.</span>"]},{"cell_type":"markdown","metadata":{},"source":["Please note that this content is made available to foster Embedded AI technology adoption. The content may include systems & methods pending patent with USPTO and protected under US Patent Laws. For redistribution of this content, IBM will use release process. For any questions please log an issue in the [GitHub](https://github.com/ibm-build-labs/Watson-NLP). \n","\n","Developed by IBM Build Lab \n","\n","Copyright - 2022 IBM Corporation "]}],"metadata":{"kernelspec":{"display_name":"Python 3.10 + GPU","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":1}
