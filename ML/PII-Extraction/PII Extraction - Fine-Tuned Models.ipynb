{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the Personal Identifiable Information (PII) using Watson NLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use Case</h2>\n",
    "\n",
    "This notebook demonstrates how to extract PII entities using Watson NLP Custom train or Fine-tune models. PII extraction is the process of identifying and extracting personal information from a document or dataset. This information can include names, addresses, phone numbers, email addresses, Social Security numbers, Credit Card number, and other types of information that can be used to identify an individual. \n",
    "\n",
    "<h2>What you'll learn in this notebook</h2>\n",
    "\n",
    "Watson NLP offers  fine-tune functionality for custom training. This notebooks shows:\n",
    "\n",
    "* <b>BILSTM</b>: the BiLSTM network would take the preprocessed text as input and learn to identify patterns and relationships between words that are indicative of PII data. The BiLSTM network would then output a probability score for each word in the text, indicating the likelihood that the word is part of a PII entity. The BiLSTM network may also be trained to recognize specific entities such as names, addresses, phone numbers, email addresses, etc.\n",
    "\n",
    "\n",
    "* <b>SIRE</b>: Statistical Information and Relation Extraction (SIRE) is a technique used in natural language processing (NLP) to extract specific information and relationships from text. It involves using machine learning algorithms to identify and extract structured data such as entities, attributes, and relations from unstructured text. SIRE is used in a variety of applications, including information extraction, knowledge graph construction, and question answering. SIRE typically uses supervised learning approach, where a model is trained using annotated examples of text and the corresponding structured data. The model can then be used to extract the same information from new, unseen text.\n",
    "\n",
    "* <b>BERT</b>: Bidirectional Encoder Representations from Transformers is a pre-trained natural language processing model  that can be fine-tuned on specific language tasks with smaller amounts of task-specific data to achieve state-of-the-art results. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "1. [Before you start](#beforeYouStart)\n",
    "1. [Load Entity PII Models](#LoadModel)\n",
    "1. [Load PII XLSX Dataset from Data Assets](#Loaddata)\n",
    "1. [TrainingData](#TrainingData)\n",
    "1. [Watson NLP Models](#NLPModels)    \n",
    "   1.  [BiLSTM Fine-tuned](#BILSTMFINE)\n",
    "   1.  [SIRE Fine-tuned](#SIRETune)\n",
    "   1.  [Transformer Fine-tuned](#TransTUne)\n",
    "1. [Fine-Tune Model For Driving License Number](#DLNFine)  \n",
    "   1.  [Sire Fine-Tune Model For Driving License Number Extraction](#SireDLNFine)\n",
    "   1.  [RBR Fine-Tune Model For Driving License Number Extraction](#RBRDLNFine)\n",
    "1. [Additional PII Entities extraction](#addPII)\n",
    "   1.   [Preparing PII Training Data](#PIIData)\n",
    "1. [Model Building on Custom PII Entities](#buildModel)\n",
    "   1.   [SIRE Training](#sire)\n",
    "   1.   [BiLSTM Training](#bilstm)\n",
    "1. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"beforeYouStart\"></a>\n",
    "### 1. Before you start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Stop kernel of other notebooks.</b></div>\n",
    "\n",
    "**Note:** If you have other notebooks currently running with the _Default Python 3.x environment, **stop their kernels** before running this notebook. All these notebooks share the same runtime environment, and if they are running in parallel, you may encounter memory issues. To stop the kernel of another notebook, open that notebook, and select _File > Stop Kernel_.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Set Project token.</b></div>\n",
    "\n",
    "Before you can begin working on this notebook in Watson Studio in Cloud Pak for Data as a Service, you need to ensure that the project token is set so that you can access the project assets via the notebook.\n",
    "\n",
    "When this notebook is added to the project, a project access token should be inserted at the top of the notebook in a code cell. If you do not see the cell above, add the token to the notebook by clicking **More > Insert project token** from the notebook action bar.  By running the inserted hidden code cell, a project object is created that you can use to access project resources.\n",
    "\n",
    "![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Cell execution</div>\n",
    "\n",
    "Note that you can step through the notebook execution cell by cell, by selecting Shift-Enter. Or you can execute the entire notebook by selecting **Cell -> Run All** from the menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import watson_nlp\n",
    "from watson_nlp import data_model as dm\n",
    "from watson_nlp.toolkit.entity_mentions_utils import prepare_train_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence Tensorflow warnings\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"LoadModel\"></a>\n",
    "### 2. Load Entity PII Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a syntax model to split the text into sentences and tokens\n",
    "syntax_model = watson_nlp.load(watson_nlp.download('syntax_izumo_en_stock'))\n",
    "# Load bilstm model in WatsonNLP\n",
    "bilstm_model = watson_nlp.load(watson_nlp.download('entity-mentions_bilstm_en_pii'))\n",
    "# Download the GloVe model to be used as embeddings in the BiLSTM\n",
    "glove_model = watson_nlp.load(watson_nlp.download('embedding_glove_en_stock'))\n",
    "# Download the algorithm template\n",
    "mentions_train_template = watson_nlp.load(watson_nlp.download('file_path_entity-mentions_sire_multi_template-crf'))\n",
    "# Download the feature extractor\n",
    "default_feature_extractor = watson_nlp.load(watson_nlp.download('feature-extractor_rbr_entity-mentions_sire_en_stock'))\n",
    "# Load rbr model in WatsonNLP\n",
    "rbr_model = watson_nlp.load(watson_nlp.download('entity-mentions_rbr_multi_pii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Loaddata\"></a>\n",
    "### 3. Load PII XLSX Dataset from Data Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First and Last Name</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Credit Card Number</th>\n",
       "      <th>First and Last Name.1</th>\n",
       "      <th>SSN.1</th>\n",
       "      <th>Credit Card Number.1</th>\n",
       "      <th>First and Last Name.2</th>\n",
       "      <th>SSN.2</th>\n",
       "      <th>Credit Card Number.2</th>\n",
       "      <th>First and Last Name.3</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit Card Number.3</th>\n",
       "      <th>First and Last Name.4</th>\n",
       "      <th>SSN.4</th>\n",
       "      <th>Credit Card Number.4</th>\n",
       "      <th>First and Last Name.5</th>\n",
       "      <th>SSN.5</th>\n",
       "      <th>Credit Card Number.5</th>\n",
       "      <th>First and Last Name.6</th>\n",
       "      <th>SSN.6</th>\n",
       "      <th>Credit Card Number.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robert Aragon</td>\n",
       "      <td>489-36-8350</td>\n",
       "      <td>4929-3813-3266-4295</td>\n",
       "      <td>Robert Aragon</td>\n",
       "      <td>489-36-8351</td>\n",
       "      <td>4929-3813-3266-4296</td>\n",
       "      <td>Robert Aragon</td>\n",
       "      <td>489-36-8352</td>\n",
       "      <td>4929-3813-3266-4297</td>\n",
       "      <td>Robert Aragon</td>\n",
       "      <td>...</td>\n",
       "      <td>4929-3813-3266-4298</td>\n",
       "      <td>Robert Aragon</td>\n",
       "      <td>489-36-8354</td>\n",
       "      <td>4929-3813-3266-4299</td>\n",
       "      <td>Robert Aragon</td>\n",
       "      <td>489-36-8355</td>\n",
       "      <td>4929-3813-3266-4300</td>\n",
       "      <td>Robert Aragon</td>\n",
       "      <td>489-36-8355</td>\n",
       "      <td>4929-3813-3266-4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashley Borden</td>\n",
       "      <td>514-14-8905</td>\n",
       "      <td>5370-4638-8881-3020</td>\n",
       "      <td>Ashley Borden</td>\n",
       "      <td>514-14-8906</td>\n",
       "      <td>5370-4638-8881-3021</td>\n",
       "      <td>Ashley Borden</td>\n",
       "      <td>514-14-8907</td>\n",
       "      <td>5370-4638-8881-3022</td>\n",
       "      <td>Ashley Borden</td>\n",
       "      <td>...</td>\n",
       "      <td>5370-4638-8881-3023</td>\n",
       "      <td>Ashley Borden</td>\n",
       "      <td>514-14-8909</td>\n",
       "      <td>5370-4638-8881-3024</td>\n",
       "      <td>Ashley Borden</td>\n",
       "      <td>514-14-8910</td>\n",
       "      <td>5370-4638-8881-3025</td>\n",
       "      <td>Ashley Borden</td>\n",
       "      <td>514-14-8910</td>\n",
       "      <td>5370-4638-8881-3025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thomas Conley</td>\n",
       "      <td>690-05-5315</td>\n",
       "      <td>4916-4811-5814-8111</td>\n",
       "      <td>Thomas Conley</td>\n",
       "      <td>690-05-5316</td>\n",
       "      <td>4916-4811-5814-8112</td>\n",
       "      <td>Thomas Conley</td>\n",
       "      <td>690-05-5317</td>\n",
       "      <td>4916-4811-5814-8113</td>\n",
       "      <td>Thomas Conley</td>\n",
       "      <td>...</td>\n",
       "      <td>4916-4811-5814-8114</td>\n",
       "      <td>Thomas Conley</td>\n",
       "      <td>690-05-5319</td>\n",
       "      <td>4916-4811-5814-8115</td>\n",
       "      <td>Thomas Conley</td>\n",
       "      <td>690-05-5320</td>\n",
       "      <td>4916-4811-5814-8116</td>\n",
       "      <td>Thomas Conley</td>\n",
       "      <td>690-05-5320</td>\n",
       "      <td>4916-4811-5814-8116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Susan Davis</td>\n",
       "      <td>421-37-1396</td>\n",
       "      <td>4916-4034-9269-8783</td>\n",
       "      <td>Susan Davis</td>\n",
       "      <td>421-37-1397</td>\n",
       "      <td>4916-4034-9269-8784</td>\n",
       "      <td>Susan Davis</td>\n",
       "      <td>421-37-1398</td>\n",
       "      <td>4916-4034-9269-8785</td>\n",
       "      <td>Susan Davis</td>\n",
       "      <td>...</td>\n",
       "      <td>4916-4034-9269-8786</td>\n",
       "      <td>Susan Davis</td>\n",
       "      <td>421-37-1400</td>\n",
       "      <td>4916-4034-9269-8787</td>\n",
       "      <td>Susan Davis</td>\n",
       "      <td>421-37-1401</td>\n",
       "      <td>4916-4034-9269-8788</td>\n",
       "      <td>Susan Davis</td>\n",
       "      <td>421-37-1401</td>\n",
       "      <td>4916-4034-9269-8788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Christopher Diaz</td>\n",
       "      <td>458-02-6124</td>\n",
       "      <td>5299-1561-5689-1938</td>\n",
       "      <td>Christopher Diaz</td>\n",
       "      <td>458-02-6125</td>\n",
       "      <td>5299-1561-5689-1939</td>\n",
       "      <td>Christopher Diaz</td>\n",
       "      <td>458-02-6126</td>\n",
       "      <td>5299-1561-5689-1940</td>\n",
       "      <td>Christopher Diaz</td>\n",
       "      <td>...</td>\n",
       "      <td>5299-1561-5689-1941</td>\n",
       "      <td>Christopher Diaz</td>\n",
       "      <td>458-02-6128</td>\n",
       "      <td>5299-1561-5689-1942</td>\n",
       "      <td>Christopher Diaz</td>\n",
       "      <td>458-02-6129</td>\n",
       "      <td>5299-1561-5689-1943</td>\n",
       "      <td>Christopher Diaz</td>\n",
       "      <td>458-02-6129</td>\n",
       "      <td>5299-1561-5689-1943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  First and Last Name          SSN   Credit Card Number First and Last Name.1  \\\n",
       "1       Robert Aragon  489-36-8350  4929-3813-3266-4295         Robert Aragon   \n",
       "2       Ashley Borden  514-14-8905  5370-4638-8881-3020         Ashley Borden   \n",
       "3       Thomas Conley  690-05-5315  4916-4811-5814-8111         Thomas Conley   \n",
       "4         Susan Davis  421-37-1396  4916-4034-9269-8783           Susan Davis   \n",
       "5    Christopher Diaz  458-02-6124  5299-1561-5689-1938      Christopher Diaz   \n",
       "\n",
       "         SSN.1 Credit Card Number.1 First and Last Name.2        SSN.2  \\\n",
       "1  489-36-8351  4929-3813-3266-4296         Robert Aragon  489-36-8352   \n",
       "2  514-14-8906  5370-4638-8881-3021         Ashley Borden  514-14-8907   \n",
       "3  690-05-5316  4916-4811-5814-8112         Thomas Conley  690-05-5317   \n",
       "4  421-37-1397  4916-4034-9269-8784           Susan Davis  421-37-1398   \n",
       "5  458-02-6125  5299-1561-5689-1939      Christopher Diaz  458-02-6126   \n",
       "\n",
       "  Credit Card Number.2 First and Last Name.3  ... Credit Card Number.3  \\\n",
       "1  4929-3813-3266-4297         Robert Aragon  ...  4929-3813-3266-4298   \n",
       "2  5370-4638-8881-3022         Ashley Borden  ...  5370-4638-8881-3023   \n",
       "3  4916-4811-5814-8113         Thomas Conley  ...  4916-4811-5814-8114   \n",
       "4  4916-4034-9269-8785           Susan Davis  ...  4916-4034-9269-8786   \n",
       "5  5299-1561-5689-1940      Christopher Diaz  ...  5299-1561-5689-1941   \n",
       "\n",
       "  First and Last Name.4        SSN.4 Credit Card Number.4  \\\n",
       "1         Robert Aragon  489-36-8354  4929-3813-3266-4299   \n",
       "2         Ashley Borden  514-14-8909  5370-4638-8881-3024   \n",
       "3         Thomas Conley  690-05-5319  4916-4811-5814-8115   \n",
       "4           Susan Davis  421-37-1400  4916-4034-9269-8787   \n",
       "5      Christopher Diaz  458-02-6128  5299-1561-5689-1942   \n",
       "\n",
       "  First and Last Name.5        SSN.5 Credit Card Number.5  \\\n",
       "1         Robert Aragon  489-36-8355  4929-3813-3266-4300   \n",
       "2         Ashley Borden  514-14-8910  5370-4638-8881-3025   \n",
       "3         Thomas Conley  690-05-5320  4916-4811-5814-8116   \n",
       "4           Susan Davis  421-37-1401  4916-4034-9269-8788   \n",
       "5      Christopher Diaz  458-02-6129  5299-1561-5689-1943   \n",
       "\n",
       "  First and Last Name.6        SSN.6 Credit Card Number.6  \n",
       "1         Robert Aragon  489-36-8355  4929-3813-3266-4300  \n",
       "2         Ashley Borden  514-14-8910  5370-4638-8881-3025  \n",
       "3         Thomas Conley  690-05-5320  4916-4811-5814-8116  \n",
       "4           Susan Davis  421-37-1401  4916-4034-9269-8788  \n",
       "5      Christopher Diaz  458-02-6129  5299-1561-5689-1943  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, types\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='o0avUc3SDky2d6pNzjuewCSTPPX7tQNz6BKKvL37nBL3',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1'\n",
    "object_key = '10-MB-Test.xlsx'\n",
    "\n",
    "body = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n",
    "\n",
    "df = pd.read_excel(body.read())\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"TrainingData\"></a>\n",
    "### 4. Preparing Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate sentences using the columns of PII information. Ideally, the sentences would include name, SSN, and credit card number in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(df, name_col, ssn_col, ccn_col):  \n",
    "    import random\n",
    "    \n",
    "    train_list = []\n",
    "    for i in range(1, len(df)):\n",
    "        name = df[name_col][i] \n",
    "        ssn = str(df[ssn_col][i])\n",
    "        ccn = str(df[ccn_col][i])\n",
    "        \n",
    "        text1 = \"My name is %s, and my social security number is %s. Here's the number to my Visa credit card, %s\" % (name, ssn, ccn)\n",
    "        text2 = \"%s is my social security number. The name on my American Express card %s is %s.\" % (ssn, ccn, name)\n",
    "        text3 = \"\"\n",
    "        text = random.choice([text1, text2])\n",
    "\n",
    "        name_begin = text.find(name)\n",
    "        name_end = text.find(name) + len(name)\n",
    "        ssn_begin = text.find(ssn)\n",
    "        ssn_end = text.find(ssn) + len(ssn)\n",
    "        ccn_begin = text.find(ccn)\n",
    "        ccn_end = text.find(ccn) + len(ccn)\n",
    "\n",
    "        data = {\n",
    "                    \"text\": text,\n",
    "                    \"mentions\": [\n",
    "                        {\n",
    "                            \"location\": {\n",
    "                                \"begin\": name_begin,\n",
    "                                \"end\": name_end\n",
    "                            },\n",
    "                            \"text\": name,\n",
    "                            \"type\": \"Name\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"location\": {\n",
    "                                \"begin\": ssn_begin,\n",
    "                                \"end\": ssn_end\n",
    "                            },\n",
    "                            \"text\": ssn,\n",
    "                            \"type\": \"SocialSecurityNumber\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"location\": {\n",
    "                                \"begin\": ccn_begin,\n",
    "                                \"end\": ccn_end\n",
    "                            },\n",
    "                            \"text\": ccn,\n",
    "                            \"type\": \"CreditCardNumber\"\n",
    "                        }\n",
    "                    ]   \n",
    "                }\n",
    "\n",
    "        train_list.append(data)\n",
    "    return train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = format_data(df=df, name_col='First and Last Name', ssn_col='SSN', ccn_col='Credit Card Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the sentences into a json training file and a json dev file. This will save the file to the runtime local as well as the project data assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'PII_text_train.json',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n",
       " 'asset_id': '216b85be-aabe-4ff6-b264-acd101222fbc'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('PII_text_train.json', 'w') as f:\n",
    "    json.dump(train_list, f)\n",
    "project.save_data('PII_text_train.json', data=json.dumps(train_list), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_list = format_data(df=df, name_col='First and Last Name.1', ssn_col='SSN.1', ccn_col='Credit Card Number.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'PII_text_dev.json',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n",
       " 'asset_id': '76834e31-ab93-4aca-b86b-ce6e71476478'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('PII_text_dev.json', 'w') as f:\n",
    "    json.dump(dev_list, f)\n",
    "project.save_data('PII_text_dev.json', data=json.dumps(dev_list), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is %s, and my social security number is %s. Here's the number to my Visa credit card, %s\" % (df['First and Last Name'][1], df['SSN'][1], df['Credit Card Number'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dm.DataStream.from_json_array(\"PII_text_train.json\")\n",
    "train_iob_stream = prepare_train_from_json(train_data, syntax_model)\n",
    "dev_data = dm.DataStream.from_json_array(\"PII_text_dev.json\")\n",
    "dev_iob_stream = prepare_train_from_json(dev_data, syntax_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"NLPModels\"></a>\n",
    "### 5. Watson NLP Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"BILSTMFINE\"></a>\n",
    "\n",
    "### 5.1 BiLSTM Fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2138/2138 [==============================] - 94s 44ms/step - loss: 0.0511 - val_loss: 0.0013\n",
      "2138/2138 [==============================] - 84s 39ms/step - loss: 0.0020 - val_loss: 2.1500e-04\n",
      "2138/2138 [==============================] - 84s 39ms/step - loss: 6.0722e-04 - val_loss: 4.7951e-05\n",
      "2138/2138 [==============================] - 84s 39ms/step - loss: 2.2989e-04 - val_loss: 1.1192e-05\n",
      "2138/2138 [==============================] - 84s 39ms/step - loss: 9.1768e-05 - val_loss: 2.5199e-06\n"
     ]
    }
   ],
   "source": [
    "bilstm_custom = bilstm_model.train(train_iob_stream, \n",
    "                                   dev_iob_stream, \n",
    "                                   embedding=glove_model.embedding,\n",
    "                                   #vocab_tags=None, \n",
    "                                   #char_embed_dim=32, \n",
    "                                   #dropout=0.2, \n",
    "                                   #num_oov_buckets=1, \n",
    "                                   num_train_epochs=5,\n",
    "                                   num_conf_epochs=5, \n",
    "                                   checkpoint_interval=5, \n",
    "                                   learning_rate=0.005, \n",
    "                                   #shuffle_buffer=2000, \n",
    "                                   #char_lstm_size=64, \n",
    "                                   #char_bidir=False, \n",
    "                                   lstm_size=16, \n",
    "                                   #train_batch_size=32, \n",
    "                                   #lower_case=False, \n",
    "                                   #embedding_lowercase=True, \n",
    "                                   #keep_model_artifacts=False)\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'bilstm_pii_custom',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n",
       " 'asset_id': '7cb485ec-42c3-4a4d-aa10-37502be1266f'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.save_data('bilstm_pii_custom', data=bilstm_custom.as_file_like_object(), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Robert Aragon   Type:  Name\n",
      "Text:  489-36-8350     Type:  SocialSecurityNumber\n",
      "Text:  4929-3813-3266-4295 Type:  CreditCardNumber\n"
     ]
    }
   ],
   "source": [
    "syntax_result = syntax_model.run(text)\n",
    "bilstm_result = bilstm_custom.run(syntax_result)\n",
    "\n",
    "for i in bilstm_result.mentions:\n",
    "    print(\"Text: \", i.span.text.ljust(15, \" \"), \"Type: \", i.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SIRETune\"></a>\n",
    "\n",
    "### 5.2 SIRE Fine-tuned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(watson_nlp.blocks.entity_mentions.SIRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing viterbi classifier\n",
      "\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n",
      "\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n",
      "Get Feature str 81791\n",
      "Done get feature str 81791\n",
      "done. [21\u001b[33mg\u001b[0m638\u001b[33mm\u001b[0m752\u001b[33mk\u001b[0m,11\u001b[33mg\u001b[0m89\u001b[33mm\u001b[0m684\u001b[33mk\u001b[0m]\n",
      "gramSize = 2\n",
      "number of processes: 5\n",
      "Initial processing:  (# of words: 1080738, # of sentences: 68412)\n",
      "senIndex[1] = 13683, wordIndex = 216154\n",
      "senIndex[2] = 27367, wordIndex = 432296\n",
      "senIndex[3] = 41053, wordIndex = 648455\n",
      "senIndex[4] = 54742, wordIndex = 864600\n",
      "senIndex[5] = 68411, wordIndex = 1080738\n",
      "\u001b[32m[ME_CRF::scaleModel]\u001b[0m Updater -- l1=\u001b[32m0.1\u001b[0m, l2=\u001b[32m0.005\u001b[0m, history size=\u001b[32m5\u001b[0m, progress windows size \u001b[32m20\u001b[0m\n",
      " Iteration           Obj             WErr                         Timing       %Eff        Per thread timing\n",
      "              2079758.43     15.06/ 81.86             E:5.66 s, M:0.03 s.       1.00 [m:5.63, M:5.66, av:5.66]\n",
      "         0  1183402.25     25.34/100.00             E:5.84 s, M:0.02 s.       1.00 [m:5.81, M:5.84, av:5.83]\n",
      "         1   407061.36     23.95/100.00             E:5.94 s, M:0.03 s.       1.00 [m:5.90, M:5.94, av:5.92]\n",
      "         2   237908.22     24.31/ 77.52             E:5.97 s, M:0.03 s.       1.00 [m:5.94, M:5.97, av:5.95]\n",
      "         3   105275.25      0.43/  5.03             E:5.92 s, M:0.03 s.       1.00 [m:5.88, M:5.91, av:5.90]\n",
      "         4    68461.98      0.21/  3.32             E:5.76 s, M:0.04 s.       1.00 [m:5.73, M:5.76, av:5.76]\n",
      "         5    27961.31      0.21/  3.32             E:5.87 s, M:0.03 s.       1.00 [m:5.84, M:5.87, av:5.87]\n",
      "         6    16707.01      0.09/  1.39             E:5.77 s, M:0.03 s.       1.00 [m:5.74, M:5.77, av:5.76]\n",
      "         7     4688.33      0.00/  0.00             E:5.77 s, M:0.03 s.       1.00 [m:5.75, M:5.77, av:5.77]\n",
      "         8     1420.00      0.00/  0.00             E:5.85 s, M:0.03 s.       1.00 [m:5.83, M:5.85, av:5.85]\n",
      "         9      992.46      0.00/  0.00             E:5.87 s, M:0.03 s.       1.00 [m:5.83, M:5.86, av:5.86]\n",
      "        10      842.12      0.00/  0.00             E:5.88 s, M:0.03 s.       1.00 [m:5.85, M:5.88, av:5.87]\n",
      "        11      648.08      0.00/  0.00             E:5.80 s, M:0.03 s.       1.00 [m:5.78, M:5.80, av:5.79]\n",
      "        12      581.08      0.00/  0.00             E:5.87 s, M:0.03 s.       1.00 [m:5.84, M:5.87, av:5.86]\n",
      "        13      456.61      0.00/  0.00             E:5.88 s, M:0.03 s.       1.00 [m:5.87, M:5.88, av:5.87]\n",
      "        14      248.01      0.00/  0.00             E:5.78 s, M:0.04 s.       1.00 [m:5.75, M:5.78, av:5.78]\n",
      "        15      191.85      0.00/  0.00             E:5.84 s, M:0.03 s.       1.00 [m:5.80, M:5.84, av:5.82]\n",
      "        16      171.46      0.00/  0.00             E:5.76 s, M:0.03 s.       1.00 [m:5.74, M:5.76, av:5.76]\n",
      "        17      128.27      0.00/  0.00             E:5.87 s, M:0.03 s.       1.00 [m:5.83, M:5.87, av:5.85]\n",
      "        18      113.70      0.00/  0.00             E:5.84 s, M:0.03 s.       1.00 [m:5.81, M:5.84, av:5.83]\n",
      "        19      104.04      0.00/  0.00             E:5.79 s, M:0.03 s.       1.00 [m:5.77, M:5.79, av:5.77]\n",
      "Not enough progress in the last 5 iters.. converged.\n",
      "    Thread     Total      Wait Effective      %Eff         #Sents/sec\n",
      "         0    122.13      0.01    122.12      1.00             2323.56\n",
      "         1    122.26      0.01    122.24      1.00             2356.92\n",
      "         2    122.18      0.00    122.17      1.00             2327.37\n",
      "         3    122.20      0.00    122.19      1.00             2361.26\n",
      "         4    122.27      0.00    122.27      1.00             2386.73\n",
      "Parent: the end!\n",
      "Initializing viterbi classifier\n",
      "\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n",
      "\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n"
     ]
    }
   ],
   "source": [
    "sire_custom = watson_nlp.blocks.entity_mentions.SIRE.train(train_iob_stream, \n",
    "                                                           'en', \n",
    "                                                           mentions_train_template,\n",
    "                                                           feature_extractors=[default_feature_extractor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 17897 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'file_name': 'sire_pii_custom',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n",
       " 'asset_id': '3b572121-d3e2-439d-8622-813f6536f335'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.save_data('sire_pii_custom', data=sire_custom.as_file_like_object(), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"mentions\": [\n",
       "    {\n",
       "      \"span\": {\n",
       "        \"begin\": 11,\n",
       "        \"end\": 24,\n",
       "        \"text\": \"Robert Aragon\"\n",
       "      },\n",
       "      \"type\": \"Name\",\n",
       "      \"producer_id\": null,\n",
       "      \"confidence\": 0.9993409548558251,\n",
       "      \"mention_type\": \"MENTT_UNSET\",\n",
       "      \"mention_class\": \"MENTC_UNSET\",\n",
       "      \"role\": \"\"\n",
       "    },\n",
       "    {\n",
       "      \"span\": {\n",
       "        \"begin\": 59,\n",
       "        \"end\": 70,\n",
       "        \"text\": \"489-36-8350\"\n",
       "      },\n",
       "      \"type\": \"SocialSecurityNumber\",\n",
       "      \"producer_id\": null,\n",
       "      \"confidence\": 0.9972113139661557,\n",
       "      \"mention_type\": \"MENTT_UNSET\",\n",
       "      \"mention_class\": \"MENTC_UNSET\",\n",
       "      \"role\": \"\"\n",
       "    },\n",
       "    {\n",
       "      \"span\": {\n",
       "        \"begin\": 114,\n",
       "        \"end\": 133,\n",
       "        \"text\": \"4929-3813-3266-4295\"\n",
       "      },\n",
       "      \"type\": \"CreditCardNumber\",\n",
       "      \"producer_id\": null,\n",
       "      \"confidence\": 0.998660825805895,\n",
       "      \"mention_type\": \"MENTT_UNSET\",\n",
       "      \"mention_class\": \"MENTC_UNSET\",\n",
       "      \"role\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"producer_id\": {\n",
       "    \"name\": \"SIRE Entity Mentions\",\n",
       "    \"version\": \"0.0.1\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntax_result = syntax_model.run(text)\n",
    "sire_result = sire_custom.run(syntax_result)\n",
    "sire_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"DLNFine\"></a>\n",
    "### 6. Fine-Tune Model For Driving License Number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the DLN dataset\n",
    "train_data = dm.DataStream.from_json_array(\"PII_faker_LicenseNumber_text_train.json\")\n",
    "train_iob_stream = prepare_train_from_json(train_data, syntax_model)\n",
    "\n",
    "dev_data = dm.DataStream.from_json_array(\"PII_faker_LicenseNumber_text_train.json\")\n",
    "dev_iob_stream = prepare_train_from_json(dev_data, syntax_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SireDLNFine\"></a>\n",
    "### 6.1 Sire Fine-Tune Model For Driving License Number Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing viterbi classifier\n",
      "\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n",
      "\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n",
      "Get Feature str 949962\n",
      "Done get feature str 949962\n",
      "done. [22\u001b[33mg\u001b[0m393\u001b[33mm\u001b[0m312\u001b[33mk\u001b[0m,11\u001b[33mg\u001b[0m1017\u001b[33mm\u001b[0m440\u001b[33mk\u001b[0m]\n",
      "gramSize = 2\n",
      "number of processes: 5\n",
      "Initial processing:  (# of words: 604530, # of sentences: 50156)\n",
      "senIndex[1] = 10036, wordIndex = 120907\n",
      "senIndex[2] = 20142, wordIndex = 241827\n",
      "senIndex[3] = 30110, wordIndex = 362724\n",
      "senIndex[4] = 40157, wordIndex = 483640\n",
      "senIndex[5] = 50155, wordIndex = 604530\n",
      "\u001b[32m[ME_CRF::scaleModel]\u001b[0m Updater -- l1=\u001b[32m0.1\u001b[0m, l2=\u001b[32m0.005\u001b[0m, history size=\u001b[32m5\u001b[0m, progress windows size \u001b[32m20\u001b[0m\n",
      " Iteration           Obj             WErr                         Timing       %Eff        Per thread timing\n",
      "              1164292.05     18.91/ 80.55             E:4.93 s, M:0.08 s.       1.00 [m:4.89, M:4.92, av:4.92]\n",
      "         0   629438.33     27.21/100.00             E:4.88 s, M:0.13 s.       1.00 [m:4.85, M:4.87, av:4.87]\n",
      "         1   384691.57     27.21/100.00             E:4.95 s, M:0.13 s.       1.00 [m:4.92, M:4.94, av:4.93]\n",
      "         2   224464.47     17.69/ 79.51             E:4.95 s, M:0.15 s.       1.00 [m:4.90, M:4.93, av:4.92]\n",
      "         3   103902.61      2.31/ 16.91             E:4.95 s, M:0.16 s.       1.00 [m:4.93, M:4.94, av:4.94]\n",
      "         4    33308.33      0.52/  6.27             E:4.92 s, M:0.17 s.       1.00 [m:4.88, M:4.91, av:4.91]\n",
      "         5    14928.29      0.11/  1.18             E:4.98 s, M:0.18 s.       1.00 [m:4.94, M:4.96, av:4.96]\n",
      "         6    10444.57      0.05/  0.64             E:4.82 s, M:0.19 s.       1.00 [m:4.77, M:4.81, av:4.81]\n",
      "         7     6929.39      0.03/  0.33             E:4.96 s, M:0.18 s.       1.00 [m:4.93, M:4.94, av:4.94]\n",
      "         8     4967.26      0.02/  0.25             E:4.86 s, M:0.18 s.       1.00 [m:4.83, M:4.85, av:4.84]\n",
      "         9     3770.64      0.00/  0.03             E:4.92 s, M:0.18 s.       1.00 [m:4.89, M:4.91, av:4.90]\n",
      "        10     2973.56      0.00/  0.01             E:4.89 s, M:0.18 s.       1.00 [m:4.86, M:4.88, av:4.88]\n",
      "        11     2017.93      0.00/  0.00             E:4.93 s, M:0.18 s.       1.00 [m:4.90, M:4.92, av:4.92]\n",
      "        12     1438.53      0.00/  0.00             E:4.89 s, M:0.18 s.       1.00 [m:4.85, M:4.88, av:4.88]\n",
      "        13     1056.99      0.00/  0.00             E:4.97 s, M:0.19 s.       1.00 [m:4.93, M:4.96, av:4.95]\n",
      "        14      819.62      0.00/  0.00             E:4.96 s, M:0.18 s.       1.00 [m:4.92, M:4.95, av:4.94]\n",
      "        15      546.44      0.00/  0.00             E:4.96 s, M:0.17 s.       1.00 [m:4.94, M:4.95, av:4.95]\n",
      "        16      414.80      0.00/  0.00             E:4.95 s, M:0.18 s.       1.00 [m:4.91, M:4.94, av:4.93]\n",
      "        17      326.76      0.00/  0.00             E:5.11 s, M:0.17 s.       1.00 [m:5.08, M:5.10, av:5.10]\n",
      "        18      178.69      0.00/  0.00             E:4.94 s, M:0.16 s.       1.00 [m:4.91, M:4.93, av:4.93]\n",
      "        1"
     ]
    }
   ],
   "source": [
    "#Fine-tune sire model on DLN dataset\n",
    "sire_custom = watson_nlp.blocks.entity_mentions.SIRE.train(train_iob_stream, \n",
    "                                                           'en', \n",
    "                                                           mentions_train_template,\n",
    "                                                           feature_extractors=[default_feature_extractor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9      154.25      0.00/  0.00             E:4.96 s, M:0.18 s.       1.00 [m:4.92, M:4.95, av:4.95]\n",
      "Not enough progress in the last 5 iters.. converged.\n",
      "    Thread     Total      Wait Effective      %Eff         #Sents/sec\n",
      "         0    103.27      0.02    103.24      1.00             2040.98\n",
      "         1    103.25      0.04    103.21      1.00             2062.27\n",
      "         2    103.17      0.03    103.14      1.00             2041.69\n",
      "         3    103.33      0.03    103.29      1.00             2040.51\n",
      "         4    103.28      0.05    103.23      1.00             2015.00\n",
      "Parent: the end!\n",
      "Initializing viterbi classifier\n",
      "\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n",
      "\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n",
      "Saved 24610 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'file_name': 'sire_pii_dl_custom',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n",
       " 'asset_id': '560e8d34-f492-4156-a2b4-cec4b1e6cf58'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save Fine-TUne Sire for DLN \n",
    "project.save_data('sire_pii_dl_custom', data=sire_custom.as_file_like_object(), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"My name is William Thomas. I belong to the Hawaii, My Driving License number is H12414887.\"\n",
    "text2 = \"My name is Michael Garcia. I belong to the North Carolina, My Driving License number is 656915532402.\"\n",
    "text3 = \"My name is Scott Thompson. I belong to the New York, My Driving License number is 225 961 856.\"\n",
    "text4 = \"My name is Michelle Perez. I belong to the Hawaii, My Driving License number is H30716114.\"\n",
    "text5 = \"My name is Timothy Noble. I belong to the Texas, My Driving License number is 10418683.\"\n",
    "text6 = \"My name is Jason Parks. I belong to the Colarado, My Driving License number is 31-331-5620.\"\n",
    "text7 = \"My name is Janice Hernandez. I belong to the Colarado, My Driving License number is 97-054-8209.\"\n",
    "text8 = \"My name is Zachary Flynn. I belong to the North Carolina, My Driving License number is 221653380787.\"\n",
    "text9 = \"My name is Brittney Davis. I belong to the New York, My credit card number is 4929-3813-3266-4295.\"\n",
    "text10 = \"My name is Jill Diaz. I belong to the California, My age is 26.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [text1, text2, text3, text4, text5, text6, text7, text8, text9, text10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text1 William Thomas  Type:  Name\n",
      "Text1 Hawaii          Type:  state\n",
      "Text1 H12414887       Type:  driving_license_number\n",
      "Text2 Michael Garcia  Type:  Name\n",
      "Text2 North Carolina  Type:  state\n",
      "Text2 656915532402    Type:  driving_license_number\n",
      "Text3 Scott Thompson  Type:  Name\n",
      "Text3 New York        Type:  state\n",
      "Text3 225 961 856     Type:  driving_license_number\n",
      "Text4 Michelle Perez  Type:  Name\n",
      "Text4 Hawaii          Type:  state\n",
      "Text4 H30716114       Type:  driving_license_number\n",
      "Text5 Timothy Noble   Type:  Name\n",
      "Text5 Texas           Type:  state\n",
      "Text5 10418683        Type:  driving_license_number\n",
      "Text6 Jason Parks     Type:  Name\n",
      "Text6 Colarado        Type:  state\n",
      "Text6 31-331-5620     Type:  driving_license_number\n",
      "Text7 Janice Hernandez Type:  Name\n",
      "Text7 Colarado        Type:  state\n",
      "Text7 97-054-8209     Type:  driving_license_number\n",
      "Text8 Zachary Flynn   Type:  Name\n",
      "Text8 North Carolina  Type:  state\n",
      "Text8 221653380787    Type:  driving_license_number\n",
      "Text9 Brittney Davis  Type:  Name\n",
      "Text9 New York        Type:  state\n",
      "Text9 337 740 487     Type:  driving_license_number\n",
      "Text10 978             Type:  driving_license_number\n"
     ]
    }
   ],
   "source": [
    "t=1\n",
    "for test in text:\n",
    "    syntax_result = syntax_model.run(test)\n",
    "    sire_result = sire_custom.run(syntax_result)\n",
    "    \n",
    "    for i in sire_result.mentions:\n",
    "        print(\"Text\"+str(t), i.span.text.ljust(15, \" \"), \"Type: \", i.type)\n",
    "    t+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"RBRDLNFine\"></a>\n",
    "### 6.2 RBR Fine-Tune Model For Driving License Number Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the pretrained model resource\n",
    "pretrained_model_resource = watson_nlp.load(watson_nlp.download('pretrained-model_watbert_multi_transformer_multi_uncased'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_custom = watson_nlp.blocks.entity_mentions.Transformer.train(train_iob_stream,\n",
    "                                                                         dev_iob_stream,\n",
    "                                                                         pretrained_model_resource,\n",
    "                                                                         num_train_epochs=1,\n",
    "                                                                         learning_rate=3e-5,\n",
    "                                                                         per_device_train_batch_size=1,\n",
    "                                                                         per_device_eval_batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2094] 2023-02-07 14:14:19,804 >> tokenizer config file saved in /tmp/wsuser/tmp_poajs55/.model/artifacts/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2100] 2023-02-07 14:14:19,806 >> Special tokens file saved in /tmp/wsuser/tmp_poajs55/.model/artifacts/special_tokens_map.json\n",
      "[INFO|trainer.py:2139] 2023-02-07 14:14:20,324 >> Saving model checkpoint to /tmp/wsuser/tmp_poajs55/.model/artifacts\n",
      "[INFO|configuration_utils.py:439] 2023-02-07 14:14:20,327 >> Configuration saved in /tmp/wsuser/tmp_poajs55/.model/artifacts/config.json\n",
      "[INFO|modeling_utils.py:1084] 2023-02-07 14:14:22,274 >> Model weights saved in /tmp/wsuser/tmp_poajs55/.model/artifacts/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2094] 2023-02-07 14:14:22,277 >> tokenizer config file saved in /tmp/wsuser/tmp_poajs55/.model/artifacts/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2100] 2023-02-07 14:14:22,278 >> Special tokens file saved in /tmp/wsuser/tmp_poajs55/.model/artifacts/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'file_name': 'transformer_pii_dl_custom',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n",
       " 'asset_id': '672b5a24-226f-4916-a9bd-a7659a2f1300'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.save_data('transformer_pii_dl_custom', data=transformer_custom.as_file_like_object(), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2389] 2023-02-07 14:18:46,759 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2391] 2023-02-07 14:18:46,762 >>   Num examples = 2\n",
      "[INFO|trainer.py:2394] 2023-02-07 14:18:46,763 >>   Batch size = 64\n",
      "[INFO|trainer.py:2389] 2023-02-07 14:18:46,882 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2391] 2023-02-07 14:18:46,882 >>   Num examples = 2\n",
      "[INFO|trainer.py:2394] 2023-02-07 14:18:46,883 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text1 William Thomas  Type:  Name\n",
      "Text1 Hawaii          Type:  state\n",
      "Text1 H12414887       Type:  driving_license_number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2389] 2023-02-07 14:18:46,994 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2391] 2023-02-07 14:18:46,995 >>   Num examples = 2\n",
      "[INFO|trainer.py:2394] 2023-02-07 14:18:46,995 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text2 Michael Garcia  Type:  Name\n",
      "Text2 North Carolina  Type:  state\n",
      "Text2 656915532402    Type:  driving_license_number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2389] 2023-02-07 14:18:47,107 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2391] 2023-02-07 14:18:47,108 >>   Num examples = 2\n",
      "[INFO|trainer.py:2394] 2023-02-07 14:18:47,109 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text3 Scott Thompson  Type:  Name\n",
      "Text3 New York        Type:  state\n",
      "Text3 225 961 856     Type:  driving_license_number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2389] 2023-02-07 14:18:47,219 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2391] 2023-02-07 14:18:47,219 >>   Num examples = 2\n",
      "[INFO|trainer.py:2394] 2023-02-07 14:18:47,220 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text4 Michelle Perez  Type:  Name\n",
      "Text4 Hawaii          Type:  state\n",
      "Text4 H30716114       Type:  driving_license_number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2389] 2023-02-07 14:18:47,329 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2391] 2023-02-07 14:18:47,330 >>   Num examples = 2\n",
      "[INFO|trainer.py:2394] 2023-02-07 14:18:47,331 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text5 Timothy Noble   Type:  Name\n",
      "Text5 Texas           Type:  state\n",
      "Text5 10418683        Type:  driving_license_number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2389] 2023-02-07 14:18:47,441 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2391] 2023-02-07 14:18:47,442 >>   Num examples = 2\n",
      "[INFO|trainer.py:2394] 2023-02-07 14:18:47,442 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text6 Jason Parks     Type:  Name\n",
      "Text6 Colarado        Type:  state\n",
      "Text6 31-331-5620     Type:  driving_license_number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2389] 2023-02-07 14:18:47,552 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2391] 2023-02-07 14:18:47,553 >>   Num examples = 2\n",
      "[INFO|trainer.py:2394] 2023-02-07 14:18:47,554 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text7 Janice Hernandez Type:  Name\n",
      "Text7 Colarado        Type:  state\n",
      "Text7 97-054-8209     Type:  driving_license_number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2389] 2023-02-07 14:18:47,663 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2391] 2023-02-07 14:18:47,664 >>   Num examples = 2\n",
      "[INFO|trainer.py:2394] 2023-02-07 14:18:47,665 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text8 Zachary Flynn   Type:  Name\n",
      "Text8 North Carolina  Type:  state\n",
      "Text8 221653380787    Type:  driving_license_number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2389] 2023-02-07 14:18:47,775 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2391] 2023-02-07 14:18:47,776 >>   Num examples = 2\n",
      "[INFO|trainer.py:2394] 2023-02-07 14:18:47,777 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text9 Brittney Davis  Type:  Name\n",
      "Text9 New York        Type:  state\n",
      "Text9 4929-3813-3266-4295 Type:  driving_license_number\n",
      "Text10 Jill Diaz       Type:  Name\n",
      "Text10 California      Type:  state\n",
      "Text10 26              Type:  driving_license_number\n"
     ]
    }
   ],
   "source": [
    "#Test the custom train transformer model \n",
    "\n",
    "t=1\n",
    "for test in text:\n",
    "    syntax_result = syntax_model.run(test)\n",
    "    transformer_result = transformer_custom.run(syntax_result)\n",
    "    \n",
    "    for i in transformer_result.mentions:\n",
    "        print(\"Text\"+str(t), i.span.text.ljust(15, \" \"), \"Type: \", i.type)\n",
    "    t+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"addPII\"></a>\n",
    "\n",
    "### 7. Additional PII Entities extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-17.0.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /opt/conda/envs/Python-3.10-CUDA/lib/python3.10/site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.10-CUDA/lib/python3.10/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Installing collected packages: faker\n",
      "Successfully installed faker-17.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"PIIData\"></a>\n",
    "### 7.1 Preparing PII Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the dataset using faker\n",
    "fake = Faker(locale='en_US')\n",
    "\n",
    "def format_data():\n",
    "    # Generate a random degree level\n",
    "    degree_level = fake.random_element(elements=('Bachelor\\'s', 'Master\\'s', 'Doctorate'))\n",
    "\n",
    "    # Generate a random field of study\n",
    "    field_of_study = fake.random_element(elements=('Computer Science', 'Engineering', 'Business', 'Psychology','Medical'))\n",
    "\n",
    "\n",
    "    # Generate a random prefix with 1-2 alphabets\n",
    "    prefix = ''.join(random.choices(string.ascii_uppercase, k=random.randint(1, 2)))\n",
    "    # Generate a random employee ID with the prefix and a random integer\n",
    "    employee_id = f\"{prefix}{fake.random_int(min=10000, max=99999):05d}\"\n",
    "\n",
    "    # Generate salary using faker\n",
    "    salary = str(fake.pyfloat(left_digits=5, right_digits=2, positive=True, min_value=1000, max_value=5000))\n",
    "    \n",
    "    \n",
    "    \n",
    "    text_1 = \"I studied %s in %s, My employee id is %s and salary is %s\" %(degree_level,field_of_study,employee_id,salary)\n",
    "    text_2 = \" Hello, My employee id is %s and I done my %s in %s, I am earning %s per month\" %(employee_id,degree_level, field_of_study,salary)\n",
    "    text_3 = \"My monthly Earning is %s and employee code is %s, I studied %s in %s\" %(salary,employee_id,degree_level,field_of_study)\n",
    "    text = random.choice([text_1, text_2,text_3])\n",
    "    \n",
    "    \n",
    "    field_of_study_begin = text.find(field_of_study)\n",
    "    field_of_study_end = field_of_study_begin + len(field_of_study)\n",
    "\n",
    "    degree_level_begin = text.find(degree_level)\n",
    "    degree_level_end = degree_level_begin + len(degree_level)\n",
    "  \n",
    "    employee_id_begin = text.find(employee_id)\n",
    "    employee_id_end = employee_id_begin + len(employee_id)\n",
    "\n",
    "    salary_begin = text.find(salary)\n",
    "    salary_end = salary_begin + len(salary)\n",
    "    \n",
    "    \n",
    "    data = {\n",
    "                \"text\": text,\n",
    "                \"mentions\": [\n",
    "                    {\n",
    "                        \"location\": {\n",
    "                            \"begin\": field_of_study_begin,\n",
    "                            \"end\": field_of_study_end\n",
    "                        },\n",
    "                        \"text\": field_of_study,\n",
    "                        \"type\": \"field_of_study\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"location\": {\n",
    "                            \"begin\": degree_level_begin,\n",
    "                            \"end\": degree_level_end\n",
    "                        },\n",
    "                        \"text\": degree_level,\n",
    "                        \"type\": \"degree_level\"\n",
    "                    },\n",
    "                                        {\n",
    "                        \"location\": {\n",
    "                            \"begin\": employee_id_begin,\n",
    "                            \"end\": employee_id_end\n",
    "                        },\n",
    "                        \"text\": employee_id,\n",
    "                        \"type\": \"employee_id\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"location\": {\n",
    "                            \"begin\": salary_begin,\n",
    "                            \"end\": salary_end\n",
    "                        },\n",
    "                        \"text\": salary,\n",
    "                        \"type\": \"salary\"\n",
    "                    }\n",
    "                ]   \n",
    "            }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' Hello, My employee id is I45456 and I done my Doctorate in Business, I am earning 2950.66 per month',\n",
       " 'mentions': [{'location': {'begin': 60, 'end': 68},\n",
       "   'text': 'Business',\n",
       "   'type': 'field_of_study'},\n",
       "  {'location': {'begin': 47, 'end': 56},\n",
       "   'text': 'Doctorate',\n",
       "   'type': 'degree_level'},\n",
       "  {'location': {'begin': 26, 'end': 32},\n",
       "   'text': 'I45456',\n",
       "   'type': 'employee_id'},\n",
       "  {'location': {'begin': 83, 'end': 90}, 'text': '2950.66', 'type': 'salary'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample dataset\n",
    "format_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'faker_PII_text_train.json',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n",
       " 'asset_id': 'e952dfbd-f642-4712-b7a5-deae8425af2a'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepared and store Training dataset for Driving License dataset\n",
    "train_list_faker = []\n",
    "for i in range(0, 30000):\n",
    "    train_list_faker.append(format_data())\n",
    "\n",
    "with open('faker_PII_text_train.json', 'w') as f:\n",
    "    json.dump(train_list_faker, f)\n",
    "project.save_data('faker_PII_text_train.json', data=json.dumps(train_list_faker), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'faker_PII_text_test.json',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n",
       " 'asset_id': '0059c8e9-2566-4288-a1c2-092dc29d418e'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepared and store Training dataset for Driving License dataset\n",
    "test_list_faker = []\n",
    "for i in range(0, 1000):\n",
    "    test_list_faker.append(format_data())\n",
    "\n",
    "with open('faker_PII_text_test.json', 'w') as f:\n",
    "    json.dump(test_list_faker, f)\n",
    "project.save_data('faker_PII_text_test.json', data=json.dumps(test_list_faker), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is already formatted correctly, the following process is needed to read the JSON data files from Watson Studio project assets and save them to the runtime working directory where they will be used as input for training the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dm.DataStream.from_json_array(\"faker_PII_text_train.json\")\n",
    "train_iob_stream = prepare_train_from_json(train_data, syntax_model)\n",
    "dev_data = dm.DataStream.from_json_array(\"faker_PII_text_test.json\")\n",
    "dev_iob_stream = prepare_train_from_json(dev_data, syntax_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text inputs will be converted into a streaming array where the text is broken down by the syntax model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"buildModel\"></a>\n",
    "## 8. Model Building on Custom PII Entities\n",
    "\n",
    "Entity extraction uses the entity-mentions block to encapsulate algorithms for the task of extracting mentions of entities (person, organizations, dates, locations,...) from the input text. The blocks and workflows offer implementations of strong entity extraction algorithms from each of the four families: rule-based, classic ML, deep-learning and transformers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sire\"></a>\n",
    "### 8.1 SIRE Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can train SIRE models using either CRF & Maximum Entropy template as base models. Between the two, CRF based template takes longer to train but gives better results.\n",
    "\n",
    "These algorithms accept a set of featured in the form of dictionaries and regular expressions. A set of predefined feature extractors are provided for multiple languages, and you can also define your own features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#help(watson_nlp.workflows.entity_mentions.SIRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the algorithm template\n",
    "mentions_train_template = watson_nlp.load(watson_nlp.download('file_path_entity-mentions_sire_multi_template-crf'))\n",
    "# Download the feature extractor\n",
    "default_feature_extractor = watson_nlp.load(watson_nlp.download('feature-extractor_rbr_entity-mentions_sire_en_stock'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing viterbi classifier\n",
      "\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n",
      "\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n",
      "Get Feature str 818099\n",
      "Done get feature str 818099\n",
      "done. [51\u001b[33mg\u001b[0m573\u001b[33mm\u001b[0m340\u001b[33mk\u001b[0m,8\u001b[33mg\u001b[0m985\u001b[33mm\u001b[0m520\u001b[33mk\u001b[0m]\n",
      "gramSize = 2\n",
      "number of processes: 5\n",
      "Initial processing:  (# of words: 265660, # of sentences: 20000)\n",
      "senIndex[1] = 7222, wordIndex = 53136\n",
      "senIndex[2] = 11699, wordIndex = 106285\n",
      "senIndex[3] = 14474, wordIndex = 159406\n",
      "senIndex[4] = 17249, wordIndex = 212535\n",
      "senIndex[5] = 19999, wordIndex = 265660\n",
      "\u001b[32m[ME_CRF::scaleModel]\u001b[0m Updater -- l1=\u001b[32m0.1\u001b[0m, l2=\u001b[32m0.005\u001b[0m, history size=\u001b[32m5\u001b[0m, progress windows size \u001b[32m20\u001b[0m\n",
      " Iteration           Obj             WErr                         Timing       %Eff        Per thread timing\n",
      "               543176.67      6.63/ 63.18             E:1.08 s, M:0.08 s.       1.00 [m:1.04, M:1.07, av:1.06]\n",
      "         0   240271.27     18.58/ 73.16             E:1.08 s, M:0.08 s.       1.00 [m:1.04, M:1.08, av:1.07]\n",
      "         1    54373.36      6.02/ 50.00             E:1.10 s, M:0.09 s.       1.00 [m:1.07, M:1.09, av:1.09]\n",
      "         2    25039.31      0.00/  0.00             E:1.06 s, M:0.10 s.       1.00 [m:1.02, M:1.06, av:1.05]\n",
      "         3    11123.39      0.00/  0.00             E:1.07 s, M:0.10 s.       1.00 [m:1.03, M:1.06, av:1.06]\n",
      "         4     5926.82      0.00/  0.00             E:1.06 s, M:0.12 s.       1.00 [m:1.02, M:1.05, av:1.05]\n",
      "         5     3692.24      0.00/  0.00             E:1.06 s, M:0.11 s.       1.00 [m:1.02, M:1.06, av:1.03]\n",
      "         6     2746.32      0.00/  0.00             E:1.07 s, M:0.11 s.       1.00 [m:1.02, M:1.06, av:1.06]\n",
      "         7     1449.70      0.00/  0.00             E:1.05 s, M:0.11 s.       1.00 [m:1.02, M:1.04, av:1.03]\n",
      "         8      990.55      0.00/  0.00             E:1.07 s, M:0.10 s.       1.00 [m:1.02, M:1.06, av:1.05]\n",
      "         9      823.03      0.00/  0.00             E:1.06 s, M:0.10 s.       1.00 [m:1.02, M:1.05, av:1.05]\n",
      "        10      674.95      0.00/  0.00             E:1.05 s, M:0.10 s.       1.00 [m:1.01, M:1.04, av:1.04]\n",
      "        11      551.34      0.00/  0.00             E:1.04 s, M:0.10 s.       1.00 [m:1.02, M:1.03, av:1.03]\n",
      "        12      413.89      0.00/  0.00             E:1.07 s, M:0.10 s.       1.00 [m:1.03, M:1.06, av:1.06]\n",
      "        13      234.79      0.00/  0.00             E:1.06 s, M:0.10 s.       1.00 [m:1.02, M:1.05, av:1.03]\n",
      "        14      140.28      0.00/  0.00             E:1.07 s, M:0.12 s.       1.00 [m:1.02, M:1.05, av:1.04]\n",
      "        15      110.84      0.00/  0.00             E:1.09 s, M:0.11 s.       1.00 [m:1.07, M:1.09, av:1.08]\n",
      "        16      100.09      0.00/  0.00             E:1.07 s, M:0.10 s.       1.00 [m:1.03, M:1.06, av:1.06]\n",
      "        17       87.69      0.00/  0.00             E:1.06 s, M:0.10 s.       1.00 [m:1.01, M:1.05, av:1.04]\n",
      "        18       76.74      0.00/  0.00             E:1.05 s, M:0.10 s.       1.00 [m:1.00, M:1.04, av:1.04]\n",
      "        19       61.49      0.00/  0.00             E:1.09 s, M:0.11 s.       1.00 [m:1.05, M:1.08, av:1.08]\n",
      "Not enough progress in the last 5 iters.. converged.\n",
      "    Thread     Total      Wait Effective      %Eff         #Sents/sec\n",
      "         0     21.99      0.01     21.98      1.00             3829.21\n",
      "         1     21.80      0.03     21.77      1.00             3872.01\n",
      "         2     21.81      0.01     21.80      1.00             3850.97\n",
      "         3     21.86      0.03     21.84      1.00             3818.95\n",
      "         4     21.95      0.02     21.93      1.00             3822.87\n",
      "Parent: the end!\n",
      "Initializing viterbi classifier\n",
      "\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n",
      "\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "sire_custom = watson_nlp.workflows.entity_mentions.SIRE.train(syntax_model=syntax_model,\n",
    "                                                              labeled_entity_mentions='/home/wsuser/work/', \n",
    "                                                              #labeled_entity_mentions=train_data,\n",
    "                                                              model_language='en', \n",
    "                                                              template_resource=mentions_train_template, \n",
    "                                                              feature_extractors=[default_feature_extractor], \n",
    "                                                              l1=0.1, \n",
    "                                                              l2=0.005, \n",
    "                                                              num_epochs=50, \n",
    "                                                              num_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will save the custom model to Watson Studio by using the project library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 9722 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'file_name': 'PII_sire_custom',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n",
       " 'asset_id': '0941d329-e971-45c2-b766-082fe06434a4'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "project.save_data('PII_sire_custom', data=sire_custom.as_file_like_object(), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the model on one example input from the dev dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My monthly Earning is 3608.13 and employee code is Q50443, I studied Doctorate in Business'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pd.read_json('faker_PII_text_test.json')['text'][1]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"mentions\": [\n",
       "    {\n",
       "      \"span\": {\n",
       "        \"begin\": 26,\n",
       "        \"end\": 33,\n",
       "        \"text\": \"MN34275\"\n",
       "      },\n",
       "      \"type\": \"employee_id\",\n",
       "      \"producer_id\": null,\n",
       "      \"confidence\": 0.999635088942728,\n",
       "      \"mention_type\": \"MENTT_UNSET\",\n",
       "      \"mention_class\": \"MENTC_UNSET\",\n",
       "      \"role\": \"\"\n",
       "    },\n",
       "    {\n",
       "      \"span\": {\n",
       "        \"begin\": 48,\n",
       "        \"end\": 56,\n",
       "        \"text\": \"Master's\"\n",
       "      },\n",
       "      \"type\": \"degree_level\",\n",
       "      \"producer_id\": null,\n",
       "      \"confidence\": 0.9996819393489853,\n",
       "      \"mention_type\": \"MENTT_UNSET\",\n",
       "      \"mention_class\": \"MENTC_UNSET\",\n",
       "      \"role\": \"\"\n",
       "    },\n",
       "    {\n",
       "      \"span\": {\n",
       "        \"begin\": 60,\n",
       "        \"end\": 67,\n",
       "        \"text\": \"Medical\"\n",
       "      },\n",
       "      \"type\": \"field_of_study\",\n",
       "      \"producer_id\": null,\n",
       "      \"confidence\": 0.9999710541077216,\n",
       "      \"mention_type\": \"MENTT_UNSET\",\n",
       "      \"mention_class\": \"MENTC_UNSET\",\n",
       "      \"role\": \"\"\n",
       "    },\n",
       "    {\n",
       "      \"span\": {\n",
       "        \"begin\": 82,\n",
       "        \"end\": 89,\n",
       "        \"text\": \"3362.18\"\n",
       "      },\n",
       "      \"type\": \"salary\",\n",
       "      \"producer_id\": null,\n",
       "      \"confidence\": 0.9987221851024309,\n",
       "      \"mention_type\": \"MENTT_UNSET\",\n",
       "      \"mention_class\": \"MENTC_UNSET\",\n",
       "      \"role\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"producer_id\": {\n",
       "    \"name\": \"Entity-Mentions SIRE Workflow\",\n",
       "    \"version\": \"0.0.1\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the model\n",
    "sire_result = sire_custom.run(text)\n",
    "sire_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bilstm\"></a>\n",
    "### 8.2 BiLSTM Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deep-learning algorithm used in this block performs sequence labelling based on the BiLSTM architecture followed by a CRF layer. It uses GloVe embeddings as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#help(watson_nlp.blocks.entity_mentions.BiLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the GloVe model to be used as embeddings in the BiLSTM\n",
    "glove_model = watson_nlp.load(watson_nlp.download('embedding_glove_en_stock'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0378 - val_loss: 8.1946e-04\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 7.7434e-04 - val_loss: 2.3477e-04\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 2.9687e-04 - val_loss: 1.0136e-04\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 1.4766e-04 - val_loss: 5.1206e-05\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 8.2653e-05 - val_loss: 2.7858e-05\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 4.8301e-05 - val_loss: 1.5810e-05\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 2.8883e-05 - val_loss: 9.2126e-06\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 1.8098e-05 - val_loss: 5.3823e-06\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 1.1191e-05 - val_loss: 3.2013e-06\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 6.9991e-06 - val_loss: 1.8871e-06\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 4.4510e-06 - val_loss: 1.1274e-06\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 2.7689e-06 - val_loss: 6.6009e-07\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 1.7540e-06 - val_loss: 3.8769e-07\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 1.1106e-06 - val_loss: 2.2019e-07\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 7.3754e-07 - val_loss: 1.2326e-07\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 4.5322e-07 - val_loss: 6.2069e-08\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 2.8857e-07 - val_loss: 3.3258e-08\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 1.7854e-07 - val_loss: 1.2692e-08\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 1.1706e-07 - val_loss: 4.1380e-09\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 7.7689e-08 - val_loss: 1.8308e-09\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 4.8563e-08 - val_loss: 9.2161e-10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 3.1140e-08 - val_loss: 5.1957e-10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 2.1447e-08 - val_loss: 3.5256e-10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 1.6134e-08 - val_loss: 1.9793e-10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 1.0216e-08 - val_loss: 1.7937e-10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 8.1928e-09 - val_loss: 1.1134e-10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 6.2423e-09 - val_loss: 8.0409e-11\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 4.8264e-09 - val_loss: 4.9482e-11\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 3.6093e-09 - val_loss: 4.9482e-11\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 8.1414e-09 - val_loss: 3.7112e-11\n"
     ]
    }
   ],
   "source": [
    "# Train BILSTM Model for Educational details entity\n",
    "bilstm_custom = watson_nlp.blocks.entity_mentions.BiLSTM.train(train_iob_stream,\n",
    "                                                              dev_iob_stream,\n",
    "                                                              glove_model.embedding,\n",
    "                                                              num_train_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to save the trained block model as a workflow, to be run with raw text later, we can use the following code snippet to do so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Trained block model as a workflow model \n",
    "from watson_nlp.workflows.entity_mentions.bilstm import BiLSTM \n",
    "\n",
    "mentions_workflow = BiLSTM(syntax_model, bilstm_custom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will save the custom model to Watson Studio by using the project library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'PII_workflow_bilstm_custom',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n",
       " 'asset_id': '615a3f7d-75a6-46ce-8e59-e78e7c4e26c2'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "project.save_data('PII_workflow_bilstm_custom', data=mentions_workflow.as_file_like_object(), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the model on one example input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"mentions\": [\n",
       "    {\n",
       "      \"span\": {\n",
       "        \"begin\": 22,\n",
       "        \"end\": 29,\n",
       "        \"text\": \"3608.13\"\n",
       "      },\n",
       "      \"type\": \"salary\",\n",
       "      \"producer_id\": {\n",
       "        \"name\": \"BiLSTM Entity Mentions\",\n",
       "        \"version\": \"1.0.0\"\n",
       "      },\n",
       "      \"confidence\": 1.0,\n",
       "      \"mention_type\": \"MENTT_UNSET\",\n",
       "      \"mention_class\": \"MENTC_UNSET\",\n",
       "      \"role\": \"\"\n",
       "    },\n",
       "    {\n",
       "      \"span\": {\n",
       "        \"begin\": 51,\n",
       "        \"end\": 57,\n",
       "        \"text\": \"Q50443\"\n",
       "      },\n",
       "      \"type\": \"employee_id\",\n",
       "      \"producer_id\": {\n",
       "        \"name\": \"BiLSTM Entity Mentions\",\n",
       "        \"version\": \"1.0.0\"\n",
       "      },\n",
       "      \"confidence\": 1.0,\n",
       "      \"mention_type\": \"MENTT_UNSET\",\n",
       "      \"mention_class\": \"MENTC_UNSET\",\n",
       "      \"role\": \"\"\n",
       "    },\n",
       "    {\n",
       "      \"span\": {\n",
       "        \"begin\": 69,\n",
       "        \"end\": 78,\n",
       "        \"text\": \"Doctorate\"\n",
       "      },\n",
       "      \"type\": \"degree_level\",\n",
       "      \"producer_id\": {\n",
       "        \"name\": \"BiLSTM Entity Mentions\",\n",
       "        \"version\": \"1.0.0\"\n",
       "      },\n",
       "      \"confidence\": 1.0,\n",
       "      \"mention_type\": \"MENTT_UNSET\",\n",
       "      \"mention_class\": \"MENTC_UNSET\",\n",
       "      \"role\": \"\"\n",
       "    },\n",
       "    {\n",
       "      \"span\": {\n",
       "        \"begin\": 82,\n",
       "        \"end\": 90,\n",
       "        \"text\": \"Business\"\n",
       "      },\n",
       "      \"type\": \"field_of_study\",\n",
       "      \"producer_id\": {\n",
       "        \"name\": \"BiLSTM Entity Mentions\",\n",
       "        \"version\": \"1.0.0\"\n",
       "      },\n",
       "      \"confidence\": 1.0,\n",
       "      \"mention_type\": \"MENTT_UNSET\",\n",
       "      \"mention_class\": \"MENTC_UNSET\",\n",
       "      \"role\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"producer_id\": {\n",
       "    \"name\": \"BiLSTM Entity Mentions Workflow\",\n",
       "    \"version\": \"1.0.0\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the BILSTM workflow model\n",
    "#syntax_result = syntax_model.run(text)\n",
    "bilstm_result = mentions_workflow.run(text)\n",
    "\n",
    "bilstm_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are able to run the trained models on new data. You will run the models on the test data so that the results can also be used for model evaluation.\n",
    "\n",
    "Watson NLP includes methods for quality testing supported models. Given a model and test data, a quality report can be generated. The following example includes the steps required to generate a quality report for a BiLSTM entity mention extactor model. The same example can be applied to any entity mention extractor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Only Micro_avg metrics could be calculated based on the information available for this block type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"per_class_confusion_matrix\": {\n",
      "        \"field_of_study\": {\n",
      "            \"true_positive\": 1000,\n",
      "            \"false_positive\": 0,\n",
      "            \"false_negative\": 0,\n",
      "            \"precision\": 1.0,\n",
      "            \"recall\": 1.0,\n",
      "            \"f1\": 1.0\n",
      "        },\n",
      "        \"employee_id\": {\n",
      "            \"true_positive\": 1000,\n",
      "            \"false_positive\": 0,\n",
      "            \"false_negative\": 0,\n",
      "            \"precision\": 1.0,\n",
      "            \"recall\": 1.0,\n",
      "            \"f1\": 1.0\n",
      "        },\n",
      "        \"salary\": {\n",
      "            \"true_positive\": 1000,\n",
      "            \"false_positive\": 0,\n",
      "            \"false_negative\": 0,\n",
      "            \"precision\": 1.0,\n",
      "            \"recall\": 1.0,\n",
      "            \"f1\": 1.0\n",
      "        },\n",
      "        \"degree_level\": {\n",
      "            \"true_positive\": 1000,\n",
      "            \"false_positive\": 0,\n",
      "            \"false_negative\": 0,\n",
      "            \"precision\": 1.0,\n",
      "            \"recall\": 1.0,\n",
      "            \"f1\": 1.0\n",
      "        }\n",
      "    },\n",
      "    \"macro_true_positive\": null,\n",
      "    \"macro_false_positive\": null,\n",
      "    \"macro_false_negative\": null,\n",
      "    \"macro_precision\": 1.0,\n",
      "    \"macro_recall\": 1.0,\n",
      "    \"macro_f1\": 1.0,\n",
      "    \"micro_precision\": 1.0,\n",
      "    \"micro_recall\": 1.0,\n",
      "    \"micro_f1\": 1.0,\n",
      "    \"overall_tp\": 4000,\n",
      "    \"overall_fp\": 0,\n",
      "    \"overall_fn\": 0,\n",
      "    \"detailed_metrics\": [],\n",
      "    \"micro_precision_partial_match\": 0.0,\n",
      "    \"micro_recall_partial_match\": 0.0,\n",
      "    \"micro_f1_partial_match\": 0.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Execute the model and generate the quality report\n",
    "preprocess_func = lambda raw_doc: syntax_model.run(raw_doc)\n",
    "quality_report = bilstm_custom.evaluate_quality('faker_PII_text_test.json', \n",
    "                                               preprocess_func)\n",
    "\n",
    "# Print the quality report\n",
    "print(json.dumps(quality_report, indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">This notebook shows you how to use the Watson NLP library and how quickly and easily you can train and run different PII extraction models using Watson NLP.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that this content is made available to foster Embedded AI technology adoption. The content may include systems & methods pending patent with USPTO and protected under US Patent Laws. For redistribution of this content, IBM will use release process. For any questions please log an issue in the [GitHub](https://github.com/ibm-build-labs/Watson-NLP). \n",
    "\n",
    "Developed by IBM Build Lab \n",
    "\n",
    "Copyright - 2022 IBM Corporation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
